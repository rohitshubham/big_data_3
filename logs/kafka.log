Attaching to mysimbdpbroker_rest-proxy_1, mysimbdpbroker_schema-registry_1, mysimbdpbroker_kafka_1, mysimbdpbroker_zookeeper_1
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka-rest/kafka-rest.properties
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable RP_ZOOKEEPER_CONNECT
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/server.properties
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable KAFKA_ZOOKEEPER_CONNECT
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for log.dirs with value from environment variable KAFKA_LOG_DIRS
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for schema.registry.url with value from environment variable RP_SCHEMA_REGISTRY_URL
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/server.properties
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/zookeeper.properties
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka-rest/kafka-rest.properties
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/schema-registry/schema-registry.properties
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for id with value from environment variable zk_id
[32mkafka_1            |[0m [2019-11-18 17:27:51,663] INFO KafkaConfig values: 
[36mrest-proxy_1       |[0m SLF4J: Class path contains multiple SLF4J bindings.
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for kafkastore.connection.url with value from environment variable SR_KAFKASTORE_CONNECTION_URL
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for maxClientCnxns with value from environment variable zk_maxClientCnxns
[32mkafka_1            |[0m 	advertised.host.name = null
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/schema-registry/schema-registry.properties
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for initLimit with value from environment variable zk_initLimit
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/kafka-rest/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[33mschema-registry_1  |[0m SLF4J: Class path contains multiple SLF4J bindings.
[32mkafka_1            |[0m 	metric.reporters = []
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for DATA.DIR with value from environment variable ZK_DATA_DIR
[36mrest-proxy_1       |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m 	quota.producer.default = 9223372036854775807
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for syncLimit with value from environment variable zk_syncLimit
[36mrest-proxy_1       |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m 	offsets.topic.num.partitions = 50
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for clientPort with value from environment variable zk_clientPort
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,464] INFO KafkaRestConfig values: 
[33mschema-registry_1  |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[32mkafka_1            |[0m 	log.flush.interval.messages = 9223372036854775807
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for dataDir with value from environment variable zk_dataDir
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.timeout.ms = 1000
[33mschema-registry_1  |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[32mkafka_1            |[0m 	auto.create.topics.enable = true
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for tickTime with value from environment variable zk_tickTime
[36mrest-proxy_1       |[0m 	metric.reporters = []
[33mschema-registry_1  |[0m [2019-11-18 17:27:51,960] INFO SchemaRegistryConfig values: 
[32mkafka_1            |[0m 	controller.socket.timeout.ms = 30000
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/zookeeper.properties
[36mrest-proxy_1       |[0m 	ssl.client.auth = false
[33mschema-registry_1  |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	log.flush.interval.ms = null
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,743] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[36mrest-proxy_1       |[0m 	consumer.iterator.timeout.ms = 1
[33mschema-registry_1  |[0m 	response.mediatype.default = application/vnd.schemaregistry.v1+json
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,745] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[32mkafka_1            |[0m 	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
[36mrest-proxy_1       |[0m 	response.mediatype.default = application/vnd.kafka.v1+json
[33mschema-registry_1  |[0m 	kafkastore.ssl.trustmanager.algorithm = PKIX
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,745] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	replica.socket.receive.buffer.bytes = 65536
[33mschema-registry_1  |[0m 	ssl.keystore.type = JKS
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,745] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = 
[33mschema-registry_1  |[0m 	kafkastore.topic = _schemas
[32mkafka_1            |[0m 	min.insync.replicas = 1
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,745] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[36mrest-proxy_1       |[0m 	schema.registry.url = http://localhost:8081
[32mkafka_1            |[0m 	replica.fetch.wait.max.ms = 500
[33mschema-registry_1  |[0m 	metrics.jmx.prefix = kafka.schema.registry
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,759] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[36mrest-proxy_1       |[0m 	metrics.jmx.prefix = kafka.rest
[32mkafka_1            |[0m 	num.recovery.threads.per.data.dir = 1
[33mschema-registry_1  |[0m 	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,760] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[36mrest-proxy_1       |[0m 	request.logger.name = io.confluent.rest-utils.requests
[32mkafka_1            |[0m 	ssl.keystore.type = JKS
[33mschema-registry_1  |[0m 	kafkastore.topic.replication.factor = 3
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,766] INFO Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.key.password = 
[32mkafka_1            |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[33mschema-registry_1  |[0m 	ssl.truststore.password = 
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,767] INFO Server environment:host.name=rohit-X406UAR (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = 
[32mkafka_1            |[0m 	default.replication.factor = 1
[33mschema-registry_1  |[0m 	kafkastore.timeout.ms = 500
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,767] INFO Server environment:java.version=1.8.0_91 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	id = 1
[33mschema-registry_1  |[0m 	host.name = rohit-X406UAR
[32mkafka_1            |[0m 	ssl.truststore.password = null
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,767] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	host.name = 
[32mkafka_1            |[0m 	log.preallocate = false
[33mschema-registry_1  |[0m 	schema.registry.zk.namespace = schema_registry
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,767] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	consumer.request.max.bytes = 67108864
[32mkafka_1            |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[33mschema-registry_1  |[0m 	ssl.endpoint.identification.algorithm = 
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,767] INFO Server environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	fetch.purgatory.purge.interval.requests = 1000
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.type = JKS
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = 
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,768] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m 	ssl.endpoint.identification.algorithm = null
[33mschema-registry_1  |[0m 	avro.compatibility.level = backward
[36mrest-proxy_1       |[0m 	consumer.threads = 1
[32mkafka_1            |[0m 	replica.socket.timeout.ms = 30000
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,768] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.ssl.protocol = TLS
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	message.max.bytes = 1000012
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,768] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.ssl.provider = 
[36mrest-proxy_1       |[0m 	debug = false
[32mkafka_1            |[0m 	num.io.threads = 8
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,768] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.location = 
[36mrest-proxy_1       |[0m 	listeners = []
[32mkafka_1            |[0m 	offsets.commit.required.acks = -1
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,768] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
[36mrest-proxy_1       |[0m 	ssl.provider = 
[32mkafka_1            |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,768] INFO Server environment:os.version=5.0.0-36-generic (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = []
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.type = JKS
[32mkafka_1            |[0m 	delete.topic.enable = true
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,769] INFO Server environment:user.name=confluent (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	producer.threads = 5
[33mschema-registry_1  |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	quota.window.size.seconds = 1
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,769] INFO Server environment:user.home=/home/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	shutdown.graceful.ms = 1000
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.password = 
[32mkafka_1            |[0m 	ssl.truststore.type = JKS
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,769] INFO Server environment:user.dir=/ (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = 
[33mschema-registry_1  |[0m 	access.control.allow.origin = 
[32mkafka_1            |[0m 	offsets.commit.timeout.ms = 5000
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,774] INFO tickTime set to 2000 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	response.mediatype.preferred = [application/vnd.kafka.v1+json, application/vnd.kafka+json, application/json]
[33mschema-registry_1  |[0m 	ssl.truststore.location = 
[32mkafka_1            |[0m 	quota.window.num = 11
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,775] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	consumer.request.timeout.ms = 1000
[33mschema-registry_1  |[0m 	ssl.keystore.password = 
[32mkafka_1            |[0m 	zookeeper.connect = localhost:2181
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,775] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	port = 8081
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = []
[32mkafka_1            |[0m 	authorizer.class.name = 
[35mzookeeper_1        |[0m [2019-11-18 17:17:46,785] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.location = 
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	num.replica.fetchers = 1
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/zookeeper.properties
[33mschema-registry_1  |[0m 	master.eligibility = true
[32mkafka_1            |[0m 	log.retention.ms = null
[36mrest-proxy_1       |[0m 	consumer.instance.timeout.ms = 300000
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for id with value from environment variable zk_id
[33mschema-registry_1  |[0m 	ssl.client.auth = false
[32mkafka_1            |[0m 	log.roll.jitter.hours = 0
[36mrest-proxy_1       |[0m 	access.control.allow.methods = 
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for maxClientCnxns with value from environment variable zk_maxClientCnxns
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.password = 
[32mkafka_1            |[0m 	log.cleaner.enable = true
[36mrest-proxy_1       |[0m 	consumer.iterator.backoff.ms = 50
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for initLimit with value from environment variable zk_initLimit
[33mschema-registry_1  |[0m 	kafkastore.security.protocol = PLAINTEXT
[32mkafka_1            |[0m 	offsets.load.buffer.size = 5242880
[36mrest-proxy_1       |[0m 	access.control.allow.origin = 
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for DATA.DIR with value from environment variable ZK_DATA_DIR
[33mschema-registry_1  |[0m 	ssl.trustmanager.algorithm = 
[36mrest-proxy_1       |[0m 	ssl.truststore.location = 
[32mkafka_1            |[0m 	log.cleaner.delete.retention.ms = 86400000
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for syncLimit with value from environment variable zk_syncLimit
[33mschema-registry_1  |[0m 	request.logger.name = io.confluent.rest-utils.requests
[36mrest-proxy_1       |[0m 	ssl.keystore.password = 
[32mkafka_1            |[0m 	ssl.client.auth = none
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for clientPort with value from environment variable zk_clientPort
[33mschema-registry_1  |[0m 	ssl.key.password = 
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = 
[32mkafka_1            |[0m 	controlled.shutdown.max.retries = 3
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for dataDir with value from environment variable zk_dataDir
[33mschema-registry_1  |[0m 	kafkastore.zk.session.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	zookeeper.connect = localhost:2181
[32mkafka_1            |[0m 	queued.max.requests = 500
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for tickTime with value from environment variable zk_tickTime
[33mschema-registry_1  |[0m 	kafkastore.ssl.key.password = 
[32mkafka_1            |[0m 	offsets.topic.replication.factor = 3
[36mrest-proxy_1       |[0m 	port = 8082
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/zookeeper.properties
[33mschema-registry_1  |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	log.cleaner.threads = 1
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,909] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[33mschema-registry_1  |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	sasl.kerberos.service.name = null
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.size.max = 25
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,910] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mrest-proxy_1       |[0m  (io.confluent.kafkarest.KafkaRestConfig:135)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,910] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[33mschema-registry_1  |[0m 	kafkastore.connection.url = localhost:2181
[32mkafka_1            |[0m 	socket.request.max.bytes = 104857600
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,651] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread:64)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,911] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[33mschema-registry_1  |[0m 	debug = false
[32mkafka_1            |[0m 	ssl.trustmanager.algorithm = PKIX
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,654] INFO Client environment:zookeeper.version=3.4.3-1240972, built on 02/06/2012 10:48 GMT (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,911] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[33mschema-registry_1  |[0m 	listeners = []
[32mkafka_1            |[0m 	zookeeper.session.timeout.ms = 6000
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,655] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,924] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[33mschema-registry_1  |[0m 	ssl.provider = 
[32mkafka_1            |[0m 	log.retention.bytes = -1
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,655] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,925] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[33mschema-registry_1  |[0m 	ssl.enabled.protocols = []
[32mkafka_1            |[0m 	log.message.timestamp.type = CreateTime
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,655] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,935] INFO Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	shutdown.graceful.ms = 1000
[32mkafka_1            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,655] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,936] INFO Server environment:host.name=rohit-X406UAR (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	ssl.keystore.location = 
[32mkafka_1            |[0m 	zookeeper.set.acl = false
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,655] INFO Client environment:java.class.path=:/usr/bin/../target/kafka-rest-*-development/share/java/kafka-rest/*:/usr/bin/../share/java/confluent-common/slf4j-api-1.7.6.jar:/usr/bin/../share/java/confluent-common/common-utils-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-config-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-metrics-3.0.0.jar:/usr/bin/../share/java/confluent-common/jline-0.9.94.jar:/usr/bin/../share/java/confluent-common/zkclient-0.5.jar:/usr/bin/../share/java/confluent-common/netty-3.2.2.Final.jar:/usr/bin/../share/java/confluent-common/zookeeper-3.4.3.jar:/usr/bin/../share/java/confluent-common/log4j-1.2.17.jar:/usr/bin/../share/java/confluent-common/slf4j-log4j12-1.7.6.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-json-provider-2.5.4.jar:/usr/bin/../share/java/rest-utils/jetty-server-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jboss-logging-3.1.3.GA.jar:/usr/bin/../share/java/rest-utils/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/rest-utils/javassist-3.18.1-GA.jar:/usr/bin/../share/java/rest-utils/jersey-common-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-test-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-provider-jetty-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-security-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-util-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.el-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-http-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-base-2.5.4.jar:/usr/bin/../share/java/rest-utils/hk2-utils-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.el-api-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-io-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.inject-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.annotation-api-1.2.jar:/usr/bin/../share/java/rest-utils/junit-4.12.jar:/usr/bin/../share/java/rest-utils/rest-utils-examples-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-bean-validation-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-continuation-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/classmate-1.0.0.jar:/usr/bin/../share/java/rest-utils/hamcrest-core-1.3.jar:/usr/bin/../share/java/rest-utils/hibernate-validator-5.1.2.Final.jar:/usr/bin/../share/java/rest-utils/jetty-servlets-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jersey-client-2.19.jar:/usr/bin/../share/java/rest-utils/hk2-locator-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/aopalliance-repackaged-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-container-jetty-http-2.19.jar:/usr/bin/../share/java/rest-utils/jackson-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-core-2.19.jar:/usr/bin/../share/java/rest-utils/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/rest-utils/jackson-databind-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-server-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-servlet-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/hk2-api-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jackson-core-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-media-jaxb-2.19.jar:/usr/bin/../share/java/rest-utils/jersey-guava-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-3.0.0.jar:/usr/bin/../share/java/rest-utils/jackson-module-jaxb-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/asm-debug-all-5.0.3.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-core-2.19.jar:/usr/bin/../share/java/rest-utils/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-2.19.jar:/usr/bin/../share/java/kafka-rest/lz4-1.3.0.jar:/usr/bin/../share/java/kafka-rest/paranamer-2.3.jar:/usr/bin/../share/java/kafka-rest/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka-rest/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka-rest/netty-3.7.0.Final.jar:/usr/bin/../share/java/kafka-rest/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka-rest/kafka-json-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/zkclient-0.8.jar:/usr/bin/../share/java/kafka-rest/kafka-schema-registry-client-3.0.0.jar:/usr/bin/../share/java/kafka-rest/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka-rest/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka-rest/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka-rest/kafka-rest-3.0.0.jar:/usr/bin/../share/java/kafka-rest/xz-1.0.jar:/usr/bin/../share/java/kafka-rest/log4j-1.2.15.jar:/usr/bin/../share/java/kafka-rest/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/activation-1.1.jar:/usr/bin/../share/java/kafka-rest/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka-rest/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/avro-1.7.7.jar:/usr/bin/../share/java/kafka-rest/jline-0.9.94.jar:/usr/bin/../share/java/kafka-rest/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka-rest/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka-rest/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/kafka-avro-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/mail-1.4.jar (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,936] INFO Server environment:java.version=1.8.0_91 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	ssl.cipher.suites = []
[32mkafka_1            |[0m 	connections.max.idle.ms = 600000
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,936] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,656] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	offsets.retention.minutes = 1440
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,936] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.ssl.endpoint.identification.algorithm = 
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,656] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	replica.fetch.backoff.ms = 1000
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,656] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,936] INFO Server environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.ssl.cipher.suites = 
[32mkafka_1            |[0m 	inter.broker.protocol.version = 0.10.0-IV1
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,656] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,937] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	access.control.allow.methods = 
[32mkafka_1            |[0m 	log.retention.hours = 168
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,656] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,937] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	ssl.keymanager.algorithm = 
[32mkafka_1            |[0m 	num.partitions = 1
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,937] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,656] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper:98)
[33mschema-registry_1  |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m 	broker.id.generation.enable = true
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,937] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,656] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper:98)
[33mschema-registry_1  |[0m 	kafkastore.init.timeout.ms = 60000
[32mkafka_1            |[0m 	listeners = null
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,938] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,656] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper:98)
[33mschema-registry_1  |[0m  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig:135)
[32mkafka_1            |[0m 	ssl.provider = null
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,938] INFO Server environment:os.version=5.0.0-36-generic (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,657] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper:98)
[33mschema-registry_1  |[0m [2019-11-18 17:27:52,647] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://rohit-X406UAR:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore:260)
[32mkafka_1            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,938] INFO Server environment:user.name=confluent (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,658] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@75c072cb (org.apache.zookeeper.ZooKeeper:433)
[33mschema-registry_1  |[0m [2019-11-18 17:27:52,654] WARN Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore:218)
[32mkafka_1            |[0m 	log.roll.ms = null
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,938] INFO Server environment:user.home=/home/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,666] INFO Opening socket connection to server /127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn:933)
[33mschema-registry_1  |[0m [2019-11-18 17:27:52,984] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:120)
[32mkafka_1            |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,938] INFO Server environment:user.dir=/ (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,668] INFO Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration. (org.apache.zookeeper.client.ZooKeeperSaslClient:125)
[33mschema-registry_1  |[0m [2019-11-18 17:27:52,987] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:68)
[32mkafka_1            |[0m 	ssl.cipher.suites = null
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,948] INFO tickTime set to 2000 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m [2019-11-18 17:27:53,177] INFO Wait to catch up until the offset of the last message at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore:299)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,711] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn:846)
[32mkafka_1            |[0m 	log.index.size.max.bytes = 10485760
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,949] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,199] INFO Created schema registry namespace localhost:2181/schema_registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry:199)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,718] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e7f8e6dbc0004, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn:1175)
[32mkafka_1            |[0m 	ssl.keymanager.algorithm = SunX509
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,949] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,221] INFO Successfully elected the new master: {"host":"rohit-X406UAR","port":8081,"master_eligibility":true,"version":1} (io.confluent.kafka.schemaregistry.zookeeper.ZookeeperMasterElector:83)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,719] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient:641)
[35mzookeeper_1        |[0m [2019-11-18 17:19:43,959] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m 	security.inter.broker.protocol = PLAINTEXT
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,225] INFO Successfully elected the new master: {"host":"rohit-X406UAR","port":8081,"master_eligibility":true,"version":1} (io.confluent.kafka.schemaregistry.zookeeper.ZookeeperMasterElector:83)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,946] INFO ProducerConfig values: 
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/zookeeper.properties
[32mkafka_1            |[0m 	replica.fetch.max.bytes = 1048576
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,256] INFO Logging initialized @2632ms (org.eclipse.jetty.util.log:186)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for id with value from environment variable zk_id
[32mkafka_1            |[0m 	advertised.port = null
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,266] WARN DEPRECATION warning: `listeners` configuration is not configured. Falling back to the deprecated `port` configuration. (io.confluent.rest.Application:248)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for maxClientCnxns with value from environment variable zk_maxClientCnxns
[32mkafka_1            |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,267] INFO Adding listener: http://0.0.0.0:8081 (io.confluent.rest.Application:137)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for initLimit with value from environment variable zk_initLimit
[32mkafka_1            |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,326] INFO jetty-9.2.12.v20150709 (org.eclipse.jetty.server.Server:327)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for DATA.DIR with value from environment variable ZK_DATA_DIR
[32mkafka_1            |[0m 	log.cleaner.io.buffer.size = 524288
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,762] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version:27)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for syncLimit with value from environment variable zk_syncLimit
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,867] INFO Started o.e.j.s.ServletContextHandler@7bb004b8{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for clientPort with value from environment variable zk_clientPort
[32mkafka_1            |[0m 	zookeeper.connection.timeout.ms = 6000
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,872] INFO Started NetworkTrafficServerConnector@3104351d{HTTP/1.1}{0.0.0.0:8081} (org.eclipse.jetty.server.NetworkTrafficServerConnector:266)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for dataDir with value from environment variable zk_dataDir
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,873] INFO Started @3250ms (org.eclipse.jetty.server.Server:379)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	log.roll.hours = 168
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for tickTime with value from environment variable zk_tickTime
[33mschema-registry_1  |[0m [2019-11-18 17:27:54,874] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain:45)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m 	log.cleanup.policy = delete
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/zookeeper.properties
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[33mschema-registry_1  |[0m [2019-11-18 17:29:07,488] INFO 127.0.0.1 - - [18/Nov/2019:17:29:07 +0000] "GET / HTTP/1.1" 200 2  90 (io.confluent.rest-utils.requests:77)
[32mkafka_1            |[0m 	host.name = 
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,923] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[36mrest-proxy_1       |[0m 	client.id = 
[33mschema-registry_1  |[0m [2019-11-18 19:43:12,941] INFO Stopped NetworkTrafficServerConnector@3104351d{HTTP/1.1}{0.0.0.0:8081} (org.eclipse.jetty.server.NetworkTrafficServerConnector:306)
[32mkafka_1            |[0m 	log.roll.jitter.ms = null
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,925] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	max.connections.per.ip = 2147483647
[33mschema-registry_1  |[0m [2019-11-18 19:43:12,952] INFO Stopped o.e.j.s.ServletContextHandler@7bb004b8{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:865)
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,925] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m 	offsets.topic.segment.bytes = 104857600
[33mschema-registry_1  |[0m [2019-11-18 19:43:12,953] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry:632)
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,925] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	background.threads = 10
[33mschema-registry_1  |[0m [2019-11-18 19:43:12,959] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:68)
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,925] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m 	quota.consumer.default = 9223372036854775807
[33mschema-registry_1  |[0m [2019-11-18 19:43:12,959] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:68)
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,937] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	request.timeout.ms = 30000
[33mschema-registry_1  |[0m [2019-11-18 19:43:12,960] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:68)
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,938] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m 	log.message.format.version = 0.10.0-IV1
[33mschema-registry_1  |[0m [2019-11-18 19:43:12,963] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:203)
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,943] INFO Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m 	log.index.interval.bytes = 4096
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,943] INFO Server environment:host.name=rohit-X406UAR (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/schema-registry/schema-registry.properties
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m 	log.dir = /tmp/kafka-logs
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,943] INFO Server environment:java.version=1.8.0_91 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for kafkastore.connection.url with value from environment variable SR_KAFKASTORE_CONNECTION_URL
[32mkafka_1            |[0m 	log.segment.bytes = 1073741824
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,943] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m 	log.cleaner.backoff.ms = 15000
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,943] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/schema-registry/schema-registry.properties
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m 	offset.metadata.max.bytes = 4096
[33mschema-registry_1  |[0m SLF4J: Class path contains multiple SLF4J bindings.
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,943] INFO Server environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m 	ssl.truststore.location = null
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m 	group.max.session.timeout.ms = 300000
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,944] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m 	ssl.keystore.password = null
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[33mschema-registry_1  |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,944] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m 	zookeeper.sync.time.ms = 2000
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[33mschema-registry_1  |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,944] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m 	port = 9092
[36mrest-proxy_1       |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33mschema-registry_1  |[0m [2019-11-18 21:42:40,544] INFO SchemaRegistryConfig values: 
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,944] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m 	log.retention.minutes = null
[33mschema-registry_1  |[0m 	metric.reporters = []
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,944] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m 	log.segment.delete.delay.ms = 60000
[33mschema-registry_1  |[0m 	response.mediatype.default = application/vnd.schemaregistry.v1+json
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,945] INFO Server environment:os.version=5.0.0-36-generic (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m 	log.dirs = /var/lib/kafka
[33mschema-registry_1  |[0m 	kafkastore.ssl.trustmanager.algorithm = PKIX
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m 	controlled.shutdown.enable = true
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,945] INFO Server environment:user.name=confluent (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	ssl.keystore.type = JKS
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m 	compression.type = producer
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,945] INFO Server environment:user.home=/home/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.topic = _schemas
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m 	max.connections.per.ip.overrides = 
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,945] INFO Server environment:user.dir=/ (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	metrics.jmx.prefix = kafka.schema.registry
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,949] INFO tickTime set to 2000 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,950] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.topic.replication.factor = 3
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,950] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[33mschema-registry_1  |[0m 	ssl.truststore.password = 
[32mkafka_1            |[0m 	auto.leader.rebalance.enable = true
[35mzookeeper_1        |[0m [2019-11-18 17:27:50,959] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[33mschema-registry_1  |[0m 	kafkastore.timeout.ms = 500
[32mkafka_1            |[0m 	leader.imbalance.check.interval.seconds = 300
[35mzookeeper_1        |[0m [2019-11-18 17:27:51,803] INFO Accepted socket connection from /127.0.0.1:44664 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[33mschema-registry_1  |[0m 	host.name = rohit-X406UAR
[32mkafka_1            |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[35mzookeeper_1        |[0m [2019-11-18 17:27:51,864] INFO Client attempting to establish new session at /127.0.0.1:44664 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33mschema-registry_1  |[0m 	schema.registry.zk.namespace = schema_registry
[32mkafka_1            |[0m 	replica.lag.time.max.ms = 10000
[35mzookeeper_1        |[0m [2019-11-18 17:27:51,866] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[33mschema-registry_1  |[0m 	ssl.endpoint.identification.algorithm = 
[32mkafka_1            |[0m 	num.network.threads = 3
[35mzookeeper_1        |[0m [2019-11-18 17:27:51,876] INFO Established session 0x16e7f8e6dbc0000 with negotiated timeout 6000 for client /127.0.0.1:44664 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.type = JKS
[32mkafka_1            |[0m 	ssl.key.password = null
[35mzookeeper_1        |[0m [2019-11-18 17:27:51,907] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[33mschema-registry_1  |[0m 	avro.compatibility.level = backward
[32mkafka_1            |[0m 	reserved.broker.max.id = 1000
[35mzookeeper_1        |[0m [2019-11-18 17:27:51,928] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[33mschema-registry_1  |[0m 	kafkastore.ssl.protocol = TLS
[32mkafka_1            |[0m 	metrics.num.samples = 2
[35mzookeeper_1        |[0m [2019-11-18 17:27:51,950] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m 	socket.send.buffer.bytes = 102400
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,221] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:setData cxid:0x21 zxid:0x12 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33mschema-registry_1  |[0m 	kafkastore.ssl.provider = 
[32mkafka_1            |[0m 	ssl.protocol = TLS
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,271] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:delete cxid:0x32 zxid:0x14 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.location = 
[32mkafka_1            |[0m 	socket.receive.buffer.bytes = 102400
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,348] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x39 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
[32mkafka_1            |[0m 	ssl.keystore.location = null
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,348] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x3a zxid:0x16 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.type = JKS
[32mkafka_1            |[0m 	replica.fetch.min.bytes = 1
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,362] INFO Accepted socket connection from /127.0.0.1:44666 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[33mschema-registry_1  |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	broker.rack = null
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,366] INFO Client attempting to establish new session at /127.0.0.1:44666 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.password = 
[32mkafka_1            |[0m 	unclean.leader.election.enable = true
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,368] INFO Established session 0x16e7f8e6dbc0001 with negotiated timeout 30000 for client /127.0.0.1:44666 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,968] INFO ProducerConfig values: 
[33mschema-registry_1  |[0m 	access.control.allow.origin = 
[32mkafka_1            |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,714] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0001 type:setData cxid:0x8 zxid:0x19 txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[33mschema-registry_1  |[0m 	ssl.truststore.location = 
[32mkafka_1            |[0m 	group.min.session.timeout.ms = 6000
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,723] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0001 type:create cxid:0xa zxid:0x1a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[33mschema-registry_1  |[0m 	ssl.keystore.password = 
[32mkafka_1            |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,748] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x44 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[33mschema-registry_1  |[0m 	port = 8081
[32mkafka_1            |[0m 	offsets.retention.check.interval.ms = 600000
[35mzookeeper_1        |[0m [2019-11-18 17:27:52,750] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x45 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.location = 
[32mkafka_1            |[0m 	producer.purgatory.purge.interval.requests = 1000
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,019] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:setData cxid:0x4e zxid:0x22 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m 	metrics.sample.window.ms = 30000
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,022] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x4f zxid:0x23 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	master.eligibility = true
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	broker.id = 0
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m 	offsets.topic.compression.codec = 0
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,151] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x8b zxid:0x26 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	ssl.client.auth = false
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	log.retention.check.interval.ms = 300000
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,154] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x8c zxid:0x27 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.password = 
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m 	advertised.listeners = null
[33mschema-registry_1  |[0m 	kafkastore.security.protocol = PLAINTEXT
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,167] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x90 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	leader.imbalance.per.broker.percentage = 10
[33mschema-registry_1  |[0m 	ssl.trustmanager.algorithm = 
[36mrest-proxy_1       |[0m 	client.id = producer-1
[32mkafka_1            |[0m  (kafka.server.KafkaConfig)
[33mschema-registry_1  |[0m 	request.logger.name = io.confluent.rest-utils.requests
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,188] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x96 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-18 17:27:51,698] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[33mschema-registry_1  |[0m 	ssl.key.password = 
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,198] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x99 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 17:27:51,698] INFO starting (kafka.server.KafkaServer)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,204] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x9c zxid:0x34 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	kafkastore.zk.session.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-18 17:27:51,704] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,209] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x9f zxid:0x37 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	kafkastore.ssl.key.password = 
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 17:27:51,714] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,230] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xa2 zxid:0x3a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[33mschema-registry_1  |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 17:27:51,719] INFO Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.ZooKeeper)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,240] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xa5 zxid:0x3d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	retries = 0
[33mschema-registry_1  |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 17:27:51,719] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,245] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xa8 zxid:0x40 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[33mschema-registry_1  |[0m 	kafkastore.ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 17:27:51,719] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,250] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xab zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-18 17:27:51,719] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[33mschema-registry_1  |[0m 	kafkastore.connection.url = localhost:2181
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,271] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xae zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,282] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xb3 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-18 17:27:51,719] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[33mschema-registry_1  |[0m 	debug = false
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,286] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xb7 zxid:0x4c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 17:27:51,719] INFO Client environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.ZooKeeper)
[33mschema-registry_1  |[0m 	listeners = []
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 17:27:51,720] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[33mschema-registry_1  |[0m 	ssl.provider = 
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,301] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xba zxid:0x4f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:51,720] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33mschema-registry_1  |[0m 	ssl.enabled.protocols = []
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,317] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xbd zxid:0x52 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:51,720] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[33mschema-registry_1  |[0m 	shutdown.graceful.ms = 1000
[32mkafka_1            |[0m [2019-11-18 17:27:51,720] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[33mschema-registry_1  |[0m 	ssl.keystore.location = 
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,321] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xc0 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:51,720] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33mschema-registry_1  |[0m 	ssl.cipher.suites = []
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,326] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xc3 zxid:0x58 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:51,720] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[33mschema-registry_1  |[0m 	kafkastore.ssl.endpoint.identification.algorithm = 
[32mkafka_1            |[0m [2019-11-18 17:27:51,720] INFO Client environment:user.name=confluent (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33mschema-registry_1  |[0m 	kafkastore.ssl.cipher.suites = 
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,343] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xc6 zxid:0x5b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:51,720] INFO Client environment:user.home=/home/confluent (org.apache.zookeeper.ZooKeeper)
[33mschema-registry_1  |[0m 	access.control.allow.methods = 
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,359] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xc9 zxid:0x5e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[33mschema-registry_1  |[0m 	ssl.keymanager.algorithm = 
[32mkafka_1            |[0m [2019-11-18 17:27:51,720] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,364] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xcc zxid:0x61 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 17:27:51,721] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@63355449 (org.apache.zookeeper.ZooKeeper)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,369] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xcf zxid:0x64 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[33mschema-registry_1  |[0m 	kafkastore.init.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 17:27:51,733] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,389] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xd4 zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[33mschema-registry_1  |[0m  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig:135)
[32mkafka_1            |[0m [2019-11-18 17:27:51,735] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,394] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xd7 zxid:0x6a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m [2019-11-18 21:42:40,997] ERROR Server died unexpectedly:  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain:51)
[32mkafka_1            |[0m [2019-11-18 17:27:51,802] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,398] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xdb zxid:0x6d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m org.apache.kafka.common.config.ConfigException: Only plaintext and SSL Kafka endpoints are supported and none are configured.
[32mkafka_1            |[0m [2019-11-18 17:27:51,878] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e7f8e6dbc0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,408] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xde zxid:0x70 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getBrokerEndpoints(KafkaStore.java:254)
[32mkafka_1            |[0m [2019-11-18 17:27:51,880] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.storage.KafkaStore.<init>(KafkaStore.java:111)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,429] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xe1 zxid:0x73 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:136)
[32mkafka_1            |[0m [2019-11-18 17:27:51,987] INFO Loading logs. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.setupResources(SchemaRegistryRestApplication.java:53)
[32mkafka_1            |[0m [2019-11-18 17:27:51,994] INFO Logs loading complete. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,433] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xe4 zxid:0x76 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.setupResources(SchemaRegistryRestApplication.java:37)
[32mkafka_1            |[0m [2019-11-18 17:27:52,063] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,437] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xe7 zxid:0x79 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33mschema-registry_1  |[0m 	at io.confluent.rest.Application.createServer(Application.java:117)
[32mkafka_1            |[0m [2019-11-18 17:27:52,065] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,447] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xea zxid:0x7c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
[32mkafka_1            |[0m [2019-11-18 17:27:52,069] WARN No meta.properties file under dir /var/lib/kafka/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,470] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xed zxid:0x7f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/schema-registry/schema-registry.properties
[32mkafka_1            |[0m [2019-11-18 17:27:52,111] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,476] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xf0 zxid:0x82 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for kafkastore.connection.url with value from environment variable SR_KAFKASTORE_CONNECTION_URL
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-18 17:27:52,126] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,484] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xf5 zxid:0x85 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/schema-registry/schema-registry.properties
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-18 17:27:52,146] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,509] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xf9 zxid:0x88 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[33mschema-registry_1  |[0m SLF4J: Class path contains multiple SLF4J bindings.
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,522] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xfc zxid:0x8b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:52,148] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,531] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0xff zxid:0x8e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 17:27:52,210] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,538] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x102 zxid:0x91 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 17:27:52,217] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,562] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x105 zxid:0x94 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-18 17:27:52,218] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,575] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x108 zxid:0x97 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-18 17:27:52,277] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,582] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x10b zxid:0x9a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m [2019-11-18 21:43:22,424] INFO SchemaRegistryConfig values: 
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-18 17:27:52,278] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,590] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x110 zxid:0x9d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	metric.reporters = []
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,970] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,613] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x114 zxid:0xa0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:52,290] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[33mschema-registry_1  |[0m 	response.mediatype.default = application/vnd.schemaregistry.v1+json
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,970] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,627] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x117 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:52,291] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[33mschema-registry_1  |[0m 	kafkastore.ssl.trustmanager.algorithm = PKIX
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,970] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,635] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x11a zxid:0xa6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:52,293] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[33mschema-registry_1  |[0m 	ssl.keystore.type = JKS
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,971] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,653] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x11d zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:52,304] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[33mschema-registry_1  |[0m 	kafkastore.topic = _schemas
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,973] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m [2019-11-18 17:27:52,305] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,673] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x120 zxid:0xac txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	metrics.jmx.prefix = kafka.schema.registry
[32mkafka_1            |[0m [2019-11-18 17:27:52,325] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,973] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,683] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x123 zxid:0xaf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:52,346] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,694] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x127 zxid:0xb2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,975] INFO KafkaJsonSerializerConfig values: 
[33mschema-registry_1  |[0m 	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
[32mkafka_1            |[0m [2019-11-18 17:27:52,354] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,716] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x12c zxid:0xb5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	json.indent.output = false
[33mschema-registry_1  |[0m 	kafkastore.topic.replication.factor = 3
[32mkafka_1            |[0m [2019-11-18 17:27:52,361] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,737] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x12f zxid:0xb8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig:135)
[33mschema-registry_1  |[0m 	ssl.truststore.password = 
[32mkafka_1            |[0m [2019-11-18 17:27:52,362] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(rohit-X406UAR,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,975] INFO KafkaJsonSerializerConfig values: 
[33mschema-registry_1  |[0m 	kafkastore.timeout.ms = 500
[35mzookeeper_1        |[0m [2019-11-18 17:27:53,748] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x132 zxid:0xbb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:52,363] WARN No meta.properties file under dir /var/lib/kafka/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[36mrest-proxy_1       |[0m 	json.indent.output = false
[33mschema-registry_1  |[0m 	host.name = rohit-X406UAR
[35mzookeeper_1        |[0m [2019-11-18 17:27:54,191] INFO Accepted socket connection from /127.0.0.1:44680 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:52,393] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig:135)
[33mschema-registry_1  |[0m 	schema.registry.zk.namespace = schema_registry
[35mzookeeper_1        |[0m [2019-11-18 17:27:54,193] INFO Client attempting to establish new session at /127.0.0.1:44680 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:52,394] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,975] INFO ProducerConfig values: 
[33mschema-registry_1  |[0m 	ssl.endpoint.identification.algorithm = 
[32mkafka_1            |[0m [2019-11-18 17:27:52,395] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[35mzookeeper_1        |[0m [2019-11-18 17:27:54,196] INFO Established session 0x16e7f8e6dbc0002 with negotiated timeout 30000 for client /127.0.0.1:44680 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 17:27:52,799] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [_schemas,0] (kafka.server.ReplicaFetcherManager)
[35mzookeeper_1        |[0m [2019-11-18 17:27:54,200] INFO Processed session termination for sessionid: 0x16e7f8e6dbc0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[33mschema-registry_1  |[0m 	avro.compatibility.level = backward
[32mkafka_1            |[0m [2019-11-18 17:27:52,817] INFO Completed load of log _schemas-0 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 17:27:54,201] INFO Closed socket connection for client /127.0.0.1:44680 which had sessionid 0x16e7f8e6dbc0002 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[33mschema-registry_1  |[0m 	kafkastore.ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 17:27:52,820] INFO Created log for partition [_schemas,0] in /var/lib/kafka with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 17:27:54,204] INFO Accepted socket connection from /127.0.0.1:44682 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mschema-registry_1  |[0m 	kafkastore.ssl.provider = 
[32mkafka_1            |[0m [2019-11-18 17:27:52,820] INFO Partition [_schemas,0] on broker 0: No checkpointed highwatermark is found for partition [_schemas,0] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 17:27:54,204] INFO Client attempting to establish new session at /127.0.0.1:44682 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.location = 
[32mkafka_1            |[0m [2019-11-18 17:27:53,028] INFO Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}} (kafka.admin.AdminUtils$)
[35mzookeeper_1        |[0m [2019-11-18 17:27:54,205] INFO Established session 0x16e7f8e6dbc0003 with negotiated timeout 30000 for client /127.0.0.1:44682 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[33mschema-registry_1  |[0m 	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
[32mkafka_1            |[0m [2019-11-18 17:27:53,031] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[35mzookeeper_1        |[0m [2019-11-18 17:27:54,222] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0003 type:create cxid:0x5 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 17:27:53,825] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[35mzookeeper_1        |[0m [2019-11-18 17:28:02,711] INFO Accepted socket connection from /127.0.0.1:44686 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[33mschema-registry_1  |[0m 	ssl.truststore.type = JKS
[35mzookeeper_1        |[0m [2019-11-18 17:28:02,713] INFO Client attempting to establish new session at /127.0.0.1:44686 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,829] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.password = 
[35mzookeeper_1        |[0m [2019-11-18 17:28:02,717] INFO Established session 0x16e7f8e6dbc0004 with negotiated timeout 30000 for client /127.0.0.1:44686 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,831] INFO Created log for partition [__consumer_offsets,0] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[33mschema-registry_1  |[0m 	access.control.allow.origin = 
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,818] INFO Accepted socket connection from /127.0.0.1:44698 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:53,832] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	client.id = 
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,819] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m 	ssl.truststore.location = 
[32mkafka_1            |[0m [2019-11-18 17:27:53,835] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,819] INFO Closed socket connection for client /127.0.0.1:44698 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:53,836] INFO Created log for partition [__consumer_offsets,29] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	ssl.keystore.password = 
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,819] INFO Accepted socket connection from /127.0.0.1:44700 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:53,836] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	port = 8081
[36mrest-proxy_1       |[0m 	acks = 1
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,819] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.location = 
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 17:27:53,840] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,820] INFO Closed socket connection for client /127.0.0.1:44700 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[33mschema-registry_1  |[0m 	master.eligibility = true
[32mkafka_1            |[0m [2019-11-18 17:27:53,841] INFO Created log for partition [__consumer_offsets,48] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,820] INFO Accepted socket connection from /127.0.0.1:44702 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	retries = 0
[33mschema-registry_1  |[0m 	ssl.client.auth = false
[32mkafka_1            |[0m [2019-11-18 17:27:53,841] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.password = 
[32mkafka_1            |[0m [2019-11-18 17:27:53,844] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,820] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[33mschema-registry_1  |[0m 	kafkastore.security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-18 17:27:53,845] INFO Created log for partition [__consumer_offsets,10] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,820] INFO Closed socket connection for client /127.0.0.1:44702 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[33mschema-registry_1  |[0m 	ssl.trustmanager.algorithm = 
[32mkafka_1            |[0m [2019-11-18 17:27:53,845] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,820] INFO Accepted socket connection from /127.0.0.1:44704 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	compression.type = none
[33mschema-registry_1  |[0m 	request.logger.name = io.confluent.rest-utils.requests
[32mkafka_1            |[0m [2019-11-18 17:27:53,848] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,821] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[33mschema-registry_1  |[0m 	ssl.key.password = 
[32mkafka_1            |[0m [2019-11-18 17:27:53,849] INFO Created log for partition [__consumer_offsets,45] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,821] INFO Closed socket connection for client /127.0.0.1:44704 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[33mschema-registry_1  |[0m 	kafkastore.zk.session.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 17:27:53,850] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,821] INFO Accepted socket connection from /127.0.0.1:44706 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33mschema-registry_1  |[0m 	kafkastore.ssl.key.password = 
[32mkafka_1            |[0m [2019-11-18 17:27:53,853] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,821] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[33mschema-registry_1  |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 17:27:53,854] INFO Created log for partition [__consumer_offsets,26] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[33mschema-registry_1  |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 17:27:53,854] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,821] INFO Closed socket connection for client /127.0.0.1:44706 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keymanager.algorithm = SunX509
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m [2019-11-18 17:27:53,857] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,822] INFO Accepted socket connection from /127.0.0.1:44708 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33mschema-registry_1  |[0m 	kafkastore.connection.url = localhost:2181
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-18 17:27:53,858] INFO Created log for partition [__consumer_offsets,7] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,822] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m 	debug = false
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 17:27:53,858] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,822] INFO Closed socket connection for client /127.0.0.1:44708 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m 	listeners = []
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 17:27:53,861] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,822] INFO Accepted socket connection from /127.0.0.1:44710 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33mschema-registry_1  |[0m 	ssl.provider = 
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 17:27:53,862] INFO Created log for partition [__consumer_offsets,42] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,823] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m 	ssl.enabled.protocols = []
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 17:27:53,862] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	shutdown.graceful.ms = 1000
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,823] INFO Closed socket connection for client /127.0.0.1:44710 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 17:27:53,865] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	ssl.keystore.location = 
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,823] INFO Accepted socket connection from /127.0.0.1:44712 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 17:27:53,866] INFO Created log for partition [__consumer_offsets,4] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	ssl.cipher.suites = []
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,823] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 17:27:53,867] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	kafkastore.ssl.endpoint.identification.algorithm = 
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,823] INFO Closed socket connection for client /127.0.0.1:44712 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 17:27:53,870] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	kafkastore.ssl.cipher.suites = 
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[33mschema-registry_1  |[0m 	access.control.allow.methods = 
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,824] INFO Accepted socket connection from /127.0.0.1:44714 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:53,871] INFO Created log for partition [__consumer_offsets,23] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[33mschema-registry_1  |[0m 	ssl.keymanager.algorithm = 
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,824] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33mschema-registry_1  |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 17:27:53,872] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,824] INFO Closed socket connection for client /127.0.0.1:44714 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[33mschema-registry_1  |[0m 	kafkastore.init.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 17:27:53,876] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,824] INFO Accepted socket connection from /127.0.0.1:44716 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[33mschema-registry_1  |[0m  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig:135)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,825] WARN Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:53,877] INFO Created log for partition [__consumer_offsets,1] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m [2019-11-18 21:43:22,890] ERROR Server died unexpectedly:  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain:51)
[32mkafka_1            |[0m [2019-11-18 17:27:53,878] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[33mschema-registry_1  |[0m org.apache.kafka.common.config.ConfigException: Only plaintext and SSL Kafka endpoints are supported and none are configured.
[35mzookeeper_1        |[0m [2019-11-18 17:29:34,825] INFO Closed socket connection for client /127.0.0.1:44716 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:53,881] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getBrokerEndpoints(KafkaStore.java:254)
[35mzookeeper_1        |[0m [2019-11-18 17:56:23,986] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:setData cxid:0x173 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/config/topics/mysimbdp Error:KeeperErrorCode = NoNode for /config/topics/mysimbdp (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:53,882] INFO Created log for partition [__consumer_offsets,20] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.storage.KafkaStore.<init>(KafkaStore.java:111)
[35mzookeeper_1        |[0m [2019-11-18 17:56:23,989] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x174 zxid:0xc7 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:53,883] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:136)
[32mkafka_1            |[0m [2019-11-18 17:27:53,887] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 17:56:23,997] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x17c zxid:0xca txntype:-1 reqpath:n/a Error Path:/brokers/topics/mysimbdp/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/mysimbdp/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.setupResources(SchemaRegistryRestApplication.java:53)
[32mkafka_1            |[0m [2019-11-18 17:27:53,888] INFO Created log for partition [__consumer_offsets,39] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.setupResources(SchemaRegistryRestApplication.java:37)
[35mzookeeper_1        |[0m [2019-11-18 17:56:23,998] INFO Got user-level KeeperException when processing sessionid:0x16e7f8e6dbc0000 type:create cxid:0x17d zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/topics/mysimbdp/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/mysimbdp/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:53,888] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[33mschema-registry_1  |[0m 	at io.confluent.rest.Application.createServer(Application.java:117)
[35mzookeeper_1        |[0m [2019-11-18 19:43:12,240] INFO Processed session termination for sessionid: 0x16e7f8e6dbc0004 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:53,892] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,979] INFO ProducerConfig values: 
[35mzookeeper_1        |[0m [2019-11-18 19:43:12,245] INFO Closed socket connection for client /127.0.0.1:44686 which had sessionid 0x16e7f8e6dbc0004 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:53,894] INFO Created log for partition [__consumer_offsets,17] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
[35mzookeeper_1        |[0m [2019-11-18 19:43:12,965] INFO Processed session termination for sessionid: 0x16e7f8e6dbc0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:53,894] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/schema-registry/schema-registry.properties
[35mzookeeper_1        |[0m [2019-11-18 19:43:12,972] INFO Closed socket connection for client /127.0.0.1:44666 which had sessionid 0x16e7f8e6dbc0001 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:53,900] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[35mzookeeper_1        |[0m [2019-11-18 19:43:12,973] INFO Processed session termination for sessionid: 0x16e7f8e6dbc0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:53,901] INFO Created log for partition [__consumer_offsets,36] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for kafkastore.connection.url with value from environment variable SR_KAFKASTORE_CONNECTION_URL
[32mkafka_1            |[0m [2019-11-18 17:27:53,901] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 19:43:12,981] INFO Closed socket connection for client /127.0.0.1:44682 which had sessionid 0x16e7f8e6dbc0003 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/schema-registry/schema-registry.properties
[32mkafka_1            |[0m [2019-11-18 17:27:53,905] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 19:43:15,600] INFO Processed session termination for sessionid: 0x16e7f8e6dbc0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[33mschema-registry_1  |[0m SLF4J: Class path contains multiple SLF4J bindings.
[32mkafka_1            |[0m [2019-11-18 17:27:53,906] INFO Created log for partition [__consumer_offsets,14] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 19:43:15,602] INFO Closed socket connection for client /127.0.0.1:44664 which had sessionid 0x16e7f8e6dbc0000 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 17:27:53,906] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/zookeeper.properties
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m [2019-11-18 17:27:53,910] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for id with value from environment variable zk_id
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m [2019-11-18 17:27:53,910] INFO Created log for partition [__consumer_offsets,33] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for maxClientCnxns with value from environment variable zk_maxClientCnxns
[33mschema-registry_1  |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[36mrest-proxy_1       |[0m 	client.id = producer-2
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for initLimit with value from environment variable zk_initLimit
[32mkafka_1            |[0m [2019-11-18 17:27:53,911] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for DATA.DIR with value from environment variable ZK_DATA_DIR
[33mschema-registry_1  |[0m [2019-11-19 15:24:05,425] INFO SchemaRegistryConfig values: 
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for syncLimit with value from environment variable zk_syncLimit
[33mschema-registry_1  |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 17:27:53,914] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	acks = 1
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for clientPort with value from environment variable zk_clientPort
[33mschema-registry_1  |[0m 	response.mediatype.default = application/vnd.schemaregistry.v1+json
[32mkafka_1            |[0m [2019-11-18 17:27:53,915] INFO Created log for partition [__consumer_offsets,49] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for dataDir with value from environment variable zk_dataDir
[33mschema-registry_1  |[0m 	kafkastore.ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 17:27:53,916] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for tickTime with value from environment variable zk_tickTime
[33mschema-registry_1  |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 17:27:53,920] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	retries = 0
[33mschema-registry_1  |[0m 	kafkastore.topic = _schemas
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/zookeeper.properties
[32mkafka_1            |[0m [2019-11-18 17:27:53,921] INFO Created log for partition [__consumer_offsets,11] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[33mschema-registry_1  |[0m 	metrics.jmx.prefix = kafka.schema.registry
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,748] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[32mkafka_1            |[0m [2019-11-18 17:27:53,922] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[33mschema-registry_1  |[0m 	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
[32mkafka_1            |[0m [2019-11-18 17:27:53,926] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,750] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[33mschema-registry_1  |[0m 	kafkastore.topic.replication.factor = 3
[32mkafka_1            |[0m [2019-11-18 17:27:53,927] INFO Created log for partition [__consumer_offsets,30] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,750] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	compression.type = none
[33mschema-registry_1  |[0m 	ssl.truststore.password = 
[32mkafka_1            |[0m [2019-11-18 17:27:53,928] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,750] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[33mschema-registry_1  |[0m 	kafkastore.timeout.ms = 500
[32mkafka_1            |[0m [2019-11-18 17:27:53,931] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,750] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[33mschema-registry_1  |[0m 	host.name = rohit-X406UAR
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,764] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[32mkafka_1            |[0m [2019-11-18 17:27:53,932] INFO Created log for partition [__consumer_offsets,46] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33mschema-registry_1  |[0m 	schema.registry.zk.namespace = schema_registry
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,764] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[32mkafka_1            |[0m [2019-11-18 17:27:53,933] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[33mschema-registry_1  |[0m 	ssl.endpoint.identification.algorithm = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,772] INFO Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,936] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 17:27:53,937] INFO Created log for partition [__consumer_offsets,27] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[33mschema-registry_1  |[0m 	avro.compatibility.level = backward
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,772] INFO Server environment:host.name=rohit-X406UAR (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,937] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[33mschema-registry_1  |[0m 	kafkastore.ssl.protocol = TLS
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,772] INFO Server environment:java.version=1.8.0_91 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,941] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33mschema-registry_1  |[0m 	kafkastore.ssl.provider = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,772] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,942] INFO Created log for partition [__consumer_offsets,8] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.location = 
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,772] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,942] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[33mschema-registry_1  |[0m 	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
[32mkafka_1            |[0m [2019-11-18 17:27:53,946] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,772] INFO Server environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.type = JKS
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 17:27:53,947] INFO Created log for partition [__consumer_offsets,24] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	ssl.truststore.type = JKS
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,774] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 17:27:53,948] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.password = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,774] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 17:27:53,952] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	access.control.allow.origin = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,774] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[33mschema-registry_1  |[0m 	ssl.truststore.location = 
[32mkafka_1            |[0m [2019-11-18 17:27:53,953] INFO Created log for partition [__consumer_offsets,43] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[33mschema-registry_1  |[0m 	ssl.keystore.password = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,774] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[33mschema-registry_1  |[0m 	port = 8081
[32mkafka_1            |[0m [2019-11-18 17:27:53,953] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,774] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.location = 
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-18 17:27:53,957] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,774] INFO Server environment:os.version=5.0.0-36-generic (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	master.eligibility = true
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-18 17:27:53,957] INFO Created log for partition [__consumer_offsets,5] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,774] INFO Server environment:user.name=confluent (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	ssl.client.auth = false
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-18 17:27:53,958] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,774] INFO Server environment:user.home=/home/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.password = 
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-18 17:27:53,962] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,774] INFO Server environment:user.dir=/ (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.security.protocol = PLAINTEXT
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,781] INFO tickTime set to 2000 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,963] INFO Created log for partition [__consumer_offsets,21] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	ssl.trustmanager.algorithm = 
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,781] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,963] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	request.logger.name = io.confluent.rest-utils.requests
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,781] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,972] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[33mschema-registry_1  |[0m 	ssl.key.password = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:39,789] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:53,973] INFO Created log for partition [__consumer_offsets,2] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[33mschema-registry_1  |[0m 	kafkastore.zk.session.timeout.ms = 30000
[35mzookeeper_1        |[0m [2019-11-18 21:42:40,477] INFO Accepted socket connection from /127.0.0.1:47180 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:53,973] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[33mschema-registry_1  |[0m 	kafkastore.ssl.key.password = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:40,534] INFO Client attempting to establish new session at /127.0.0.1:47180 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,976] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33mschema-registry_1  |[0m 	metrics.num.samples = 2
[35mzookeeper_1        |[0m [2019-11-18 21:42:40,536] INFO Creating new log file: log.d3 (org.apache.zookeeper.server.persistence.FileTxnLog)
[32mkafka_1            |[0m [2019-11-18 17:27:53,977] INFO Created log for partition [__consumer_offsets,40] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[33mschema-registry_1  |[0m 	ssl.protocol = TLS
[35mzookeeper_1        |[0m [2019-11-18 21:42:40,565] INFO Established session 0x16e8077b7d30000 with negotiated timeout 6000 for client /127.0.0.1:47180 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:53,977] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keymanager.algorithm = SunX509
[35mzookeeper_1        |[0m [2019-11-18 21:42:40,861] INFO Accepted socket connection from /127.0.0.1:47182 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:53,980] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,980] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-18 21:42:40,863] INFO Client attempting to establish new session at /127.0.0.1:47182 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.connection.url = localhost:2181
[32mkafka_1            |[0m [2019-11-18 17:27:53,981] INFO Created log for partition [__consumer_offsets,37] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,980] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-18 21:42:40,865] INFO Established session 0x16e8077b7d30001 with negotiated timeout 30000 for client /127.0.0.1:47182 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	debug = false
[32mkafka_1            |[0m [2019-11-18 17:27:53,981] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,980] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-18 21:42:41,345] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m 	listeners = []
[32mkafka_1            |[0m [2019-11-18 17:27:53,985] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,980] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m EndOfStreamException: Unable to read additional data from client sessionid 0x16e8077b7d30001, likely client has closed socket
[33mschema-registry_1  |[0m 	ssl.provider = 
[32mkafka_1            |[0m [2019-11-18 17:27:53,986] INFO Created log for partition [__consumer_offsets,18] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,980] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
[32mkafka_1            |[0m [2019-11-18 17:27:53,986] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	ssl.enabled.protocols = []
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:02,980] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[32mkafka_1            |[0m [2019-11-18 17:27:53,989] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	shutdown.graceful.ms = 1000
[35mzookeeper_1        |[0m 	at java.lang.Thread.run(Thread.java:745)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,095] INFO KafkaAvroSerializerConfig values: 
[32mkafka_1            |[0m [2019-11-18 17:27:53,990] INFO Created log for partition [__consumer_offsets,34] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	ssl.keystore.location = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:41,348] INFO Closed socket connection for client /127.0.0.1:47182 which had sessionid 0x16e8077b7d30001 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[33mschema-registry_1  |[0m 	ssl.cipher.suites = []
[32mkafka_1            |[0m [2019-11-18 17:27:53,990] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:42:41,617] INFO Got user-level KeeperException when processing sessionid:0x16e8077b7d30000 type:delete cxid:0xc7 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[33mschema-registry_1  |[0m 	kafkastore.ssl.endpoint.identification.algorithm = 
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 17:27:53,994] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	kafkastore.ssl.cipher.suites = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:41,702] INFO Got user-level KeeperException when processing sessionid:0x16e8077b7d30000 type:create cxid:0xce zxid:0xd8 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,099] INFO KafkaAvroSerializerConfig values: 
[32mkafka_1            |[0m [2019-11-18 17:27:53,995] INFO Created log for partition [__consumer_offsets,15] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	access.control.allow.methods = 
[35mzookeeper_1        |[0m [2019-11-18 21:42:41,702] INFO Got user-level KeeperException when processing sessionid:0x16e8077b7d30000 type:create cxid:0xcf zxid:0xd9 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m [2019-11-18 17:27:53,995] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:42:51,115] INFO Accepted socket connection from /127.0.0.1:47188 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33mschema-registry_1  |[0m 	ssl.keymanager.algorithm = 
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m [2019-11-18 17:27:53,999] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:42:51,118] INFO Client attempting to establish new session at /127.0.0.1:47188 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	metrics.sample.window.ms = 30000
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 17:27:54,000] INFO Created log for partition [__consumer_offsets,12] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	kafkastore.init.timeout.ms = 60000
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,100] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-18 17:27:54,000] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:42:51,121] INFO Established session 0x16e8077b7d30002 with negotiated timeout 30000 for client /127.0.0.1:47188 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig:135)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 17:27:54,004] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:42:58,788] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m [2019-11-19 15:24:06,231] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://rohit-X406UAR:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore:260)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-18 17:27:54,005] INFO Created log for partition [__consumer_offsets,31] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m [2019-11-19 15:24:06,257] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore:279)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-18 17:27:54,005] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m EndOfStreamException: Unable to read additional data from client sessionid 0x16e8077b7d30002, likely client has closed socket
[33mschema-registry_1  |[0m [2019-11-19 15:24:46,531] ERROR Server died unexpectedly:  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain:51)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-18 17:27:54,008] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
[33mschema-registry_1  |[0m org.apache.kafka.common.errors.TimeoutException: Timeout expired while fetching topic metadata
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-18 17:27:54,009] INFO Created log for partition [__consumer_offsets,9] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/schema-registry/schema-registry.properties
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 17:27:54,009] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for kafkastore.connection.url with value from environment variable SR_KAFKASTORE_CONNECTION_URL
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 17:27:54,012] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m 	at java.lang.Thread.run(Thread.java:745)
[33mschema-registry_1  |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/schema-registry/schema-registry.properties
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[35mzookeeper_1        |[0m [2019-11-18 21:42:58,791] INFO Closed socket connection for client /127.0.0.1:47188 which had sessionid 0x16e8077b7d30002 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:54,012] INFO Created log for partition [__consumer_offsets,47] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m SLF4J: Class path contains multiple SLF4J bindings.
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[35mzookeeper_1        |[0m [2019-11-18 21:43:01,453] INFO Processed session termination for sessionid: 0x16e8077b7d30000 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,012] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[35mzookeeper_1        |[0m [2019-11-18 21:43:01,457] INFO Closed socket connection for client /127.0.0.1:47180 which had sessionid 0x16e8077b7d30000 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:54,016] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m SLF4J: Found binding in [jar:file:/usr/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[36mrest-proxy_1       |[0m 	client.id = 
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/zookeeper.properties
[32mkafka_1            |[0m [2019-11-18 17:27:54,017] INFO Created log for partition [__consumer_offsets,19] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-18 17:27:54,017] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for id with value from environment variable zk_id
[33mschema-registry_1  |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 17:27:54,020] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for maxClientCnxns with value from environment variable zk_maxClientCnxns
[33mschema-registry_1  |[0m [2019-11-19 15:26:32,894] INFO SchemaRegistryConfig values: 
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-18 17:27:54,021] INFO Created log for partition [__consumer_offsets,28] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for initLimit with value from environment variable zk_initLimit
[33mschema-registry_1  |[0m 	metric.reporters = []
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 17:27:54,022] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for DATA.DIR with value from environment variable ZK_DATA_DIR
[33mschema-registry_1  |[0m 	response.mediatype.default = application/vnd.schemaregistry.v1+json
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for syncLimit with value from environment variable zk_syncLimit
[32mkafka_1            |[0m [2019-11-18 17:27:54,025] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	kafkastore.ssl.trustmanager.algorithm = PKIX
[36mrest-proxy_1       |[0m 	retries = 0
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for clientPort with value from environment variable zk_clientPort
[33mschema-registry_1  |[0m 	ssl.keystore.type = JKS
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-18 17:27:54,025] INFO Created log for partition [__consumer_offsets,38] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	kafkastore.topic = _schemas
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for dataDir with value from environment variable zk_dataDir
[33mschema-registry_1  |[0m 	metrics.jmx.prefix = kafka.schema.registry
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for tickTime with value from environment variable zk_tickTime
[33mschema-registry_1  |[0m 	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
[32mkafka_1            |[0m [2019-11-18 17:27:54,026] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	compression.type = none
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/zookeeper.properties
[33mschema-registry_1  |[0m 	kafkastore.topic.replication.factor = 3
[32mkafka_1            |[0m [2019-11-18 17:27:54,029] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,628] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[33mschema-registry_1  |[0m 	ssl.truststore.password = 
[32mkafka_1            |[0m [2019-11-18 17:27:54,030] INFO Created log for partition [__consumer_offsets,35] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,631] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 17:27:54,030] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,631] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[33mschema-registry_1  |[0m 	kafkastore.timeout.ms = 500
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-18 17:27:54,033] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,631] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[33mschema-registry_1  |[0m 	host.name = rohit-X406UAR
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-18 17:27:54,034] INFO Created log for partition [__consumer_offsets,44] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,631] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[33mschema-registry_1  |[0m 	schema.registry.zk.namespace = schema_registry
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 17:27:54,034] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	ssl.endpoint.identification.algorithm = 
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,647] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 17:27:54,037] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.type = JKS
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,648] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-18 17:27:54,038] INFO Created log for partition [__consumer_offsets,6] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	avro.compatibility.level = backward
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,656] INFO Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 17:27:54,038] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	kafkastore.ssl.protocol = TLS
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,656] INFO Server environment:host.name=rohit-X406UAR (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 17:27:54,041] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	kafkastore.ssl.provider = 
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,656] INFO Server environment:java.version=1.8.0_91 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 17:27:54,042] INFO Created log for partition [__consumer_offsets,25] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.location = 
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,656] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 17:27:54,042] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,656] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 17:27:54,045] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.type = JKS
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,656] INFO Server environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 17:27:54,046] INFO Created log for partition [__consumer_offsets,16] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	ssl.truststore.type = JKS
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,657] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 17:27:54,047] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	kafkastore.ssl.truststore.password = 
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,658] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 17:27:54,050] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	access.control.allow.origin = 
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,658] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 17:27:54,051] INFO Created log for partition [__consumer_offsets,22] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	ssl.truststore.location = 
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-18 17:27:54,052] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,658] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	ssl.keystore.password = 
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,658] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,055] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[33mschema-registry_1  |[0m 	port = 8081
[36mrest-proxy_1       |[0m 	batch.size = 16384
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,658] INFO Server environment:os.version=5.0.0-36-generic (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,056] INFO Created log for partition [__consumer_offsets,41] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.location = 
[33mschema-registry_1  |[0m 	master.eligibility = true
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,658] INFO Server environment:user.name=confluent (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,056] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[33mschema-registry_1  |[0m 	ssl.client.auth = false
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,658] INFO Server environment:user.home=/home/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[33mschema-registry_1  |[0m 	kafkastore.ssl.keystore.password = 
[32mkafka_1            |[0m [2019-11-18 17:27:54,059] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,658] INFO Server environment:user.dir=/ (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	kafkastore.security.protocol = PLAINTEXT
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-18 17:27:54,060] INFO Created log for partition [__consumer_offsets,32] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,665] INFO tickTime set to 2000 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 17:27:54,061] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,665] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	ssl.trustmanager.algorithm = 
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,665] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[33mschema-registry_1  |[0m 	request.logger.name = io.confluent.rest-utils.requests
[32mkafka_1            |[0m [2019-11-18 17:27:54,064] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:43:21,676] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[33mschema-registry_1  |[0m 	ssl.key.password = 
[32mkafka_1            |[0m [2019-11-18 17:27:54,064] INFO Created log for partition [__consumer_offsets,3] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[35mzookeeper_1        |[0m [2019-11-18 21:43:22,382] INFO Accepted socket connection from /127.0.0.1:47192 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[33mschema-registry_1  |[0m 	kafkastore.zk.session.timeout.ms = 30000
[35mzookeeper_1        |[0m [2019-11-18 21:43:22,440] INFO Client attempting to establish new session at /127.0.0.1:47192 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[33mschema-registry_1  |[0m 	kafkastore.ssl.key.password = 
[32mkafka_1            |[0m [2019-11-18 17:27:54,065] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[35mzookeeper_1        |[0m [2019-11-18 21:43:22,440] INFO Creating new log file: log.111 (org.apache.zookeeper.server.persistence.FileTxnLog)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,104] INFO ProducerConfig values: 
[33mschema-registry_1  |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 17:27:54,068] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[35mzookeeper_1        |[0m [2019-11-18 21:43:22,447] INFO Established session 0x16e80785b850000 with negotiated timeout 6000 for client /127.0.0.1:47192 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	ssl.protocol = TLS
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 17:27:54,068] INFO Created log for partition [__consumer_offsets,13] in /var/lib/kafka with properties {compression.type -> uncompressed, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[33mschema-registry_1  |[0m 	kafkastore.ssl.keymanager.algorithm = SunX509
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-18 17:27:54,069] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[33mschema-registry_1  |[0m 	kafkastore.connection.url = localhost:2181
[35mzookeeper_1        |[0m [2019-11-18 21:43:22,760] INFO Accepted socket connection from /127.0.0.1:47194 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:54,073] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[33mschema-registry_1  |[0m 	debug = false
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-18 17:27:54,079] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-18 21:43:22,763] INFO Client attempting to establish new session at /127.0.0.1:47194 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	listeners = []
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-18 17:27:54,079] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-18 21:43:22,765] INFO Established session 0x16e80785b850001 with negotiated timeout 30000 for client /127.0.0.1:47194 (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	ssl.provider = 
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 17:27:54,082] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-18 21:43:23,240] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m 	ssl.enabled.protocols = []
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 17:27:54,082] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m EndOfStreamException: Unable to read additional data from client sessionid 0x16e80785b850001, likely client has closed socket
[33mschema-registry_1  |[0m 	shutdown.graceful.ms = 1000
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-18 17:27:54,085] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
[33mschema-registry_1  |[0m 	ssl.keystore.location = 
[32mkafka_1            |[0m [2019-11-18 17:27:54,086] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
[33mschema-registry_1  |[0m 	ssl.cipher.suites = []
[32mkafka_1            |[0m [2019-11-18 17:27:54,089] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[35mzookeeper_1        |[0m 	at java.lang.Thread.run(Thread.java:745)
[33mschema-registry_1  |[0m 	kafkastore.ssl.endpoint.identification.algorithm = 
[32mkafka_1            |[0m [2019-11-18 17:27:54,089] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	client.id = producer-3
[35mzookeeper_1        |[0m [2019-11-18 21:43:23,243] INFO Closed socket connection for client /127.0.0.1:47194 which had sessionid 0x16e80785b850001 (org.apache.zookeeper.server.NIOServerCnxn)
[33mschema-registry_1  |[0m 	kafkastore.ssl.cipher.suites = 
[32mkafka_1            |[0m [2019-11-18 17:27:54,092] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[35mzookeeper_1        |[0m [2019-11-18 21:43:23,453] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:delete cxid:0xc7 zxid:0x115 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	access.control.allow.methods = 
[32mkafka_1            |[0m [2019-11-18 17:27:54,092] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[35mzookeeper_1        |[0m [2019-11-18 21:43:23,518] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:create cxid:0xce zxid:0x116 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	ssl.keymanager.algorithm = 
[32mkafka_1            |[0m [2019-11-18 17:27:54,095] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	acks = 1
[35mzookeeper_1        |[0m [2019-11-18 21:43:23,519] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:create cxid:0xcf zxid:0x117 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 17:27:54,095] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[33mschema-registry_1  |[0m 	kafkastore.init.timeout.ms = 60000
[35mzookeeper_1        |[0m [2019-11-18 21:43:33,090] INFO Accepted socket connection from /127.0.0.1:47206 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:54,098] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[33mschema-registry_1  |[0m  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig:135)
[35mzookeeper_1        |[0m [2019-11-18 21:43:33,092] INFO Client attempting to establish new session at /127.0.0.1:47206 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,098] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	retries = 0
[33mschema-registry_1  |[0m [2019-11-19 15:26:33,471] ERROR Server died unexpectedly:  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain:51)
[35mzookeeper_1        |[0m [2019-11-18 21:43:33,095] INFO Established session 0x16e80785b850002 with negotiated timeout 30000 for client /127.0.0.1:47206 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,100] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[33mschema-registry_1  |[0m org.apache.kafka.common.config.ConfigException: Only plaintext and SSL Kafka endpoints are supported and none are configured.
[35mzookeeper_1        |[0m [2019-11-18 21:43:52,000] INFO Expiring session 0x16e8077b7d30002, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,100] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[35mzookeeper_1        |[0m [2019-11-18 21:43:52,001] INFO Expiring session 0x16e8077b7d30001, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.storage.KafkaStore.getBrokerEndpoints(KafkaStore.java:254)
[32mkafka_1            |[0m [2019-11-18 17:27:54,103] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[35mzookeeper_1        |[0m [2019-11-18 21:43:52,002] INFO Processed session termination for sessionid: 0x16e8077b7d30002 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.storage.KafkaStore.<init>(KafkaStore.java:111)
[32mkafka_1            |[0m [2019-11-18 17:27:54,103] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	compression.type = none
[35mzookeeper_1        |[0m [2019-11-18 21:43:52,003] INFO Processed session termination for sessionid: 0x16e8077b7d30001 (org.apache.zookeeper.server.PrepRequestProcessor)
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.<init>(KafkaSchemaRegistry.java:136)
[32mkafka_1            |[0m [2019-11-18 17:27:54,105] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[35mzookeeper_1        |[0m [2019-11-18 21:43:54,000] INFO Expiring session 0x16e80785b850001, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.setupResources(SchemaRegistryRestApplication.java:53)
[32mkafka_1            |[0m [2019-11-18 17:27:54,106] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication.setupResources(SchemaRegistryRestApplication.java:37)
[35mzookeeper_1        |[0m [2019-11-18 21:43:54,001] INFO Processed session termination for sessionid: 0x16e80785b850001 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,108] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33mschema-registry_1  |[0m 	at io.confluent.rest.Application.createServer(Application.java:117)
[35mzookeeper_1        |[0m [2019-11-18 22:10:31,541] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:setData cxid:0x173 zxid:0x151 txntype:-1 reqpath:n/a Error Path:/config/topics/mysimbdp-clientReport Error:KeeperErrorCode = NoNode for /config/topics/mysimbdp-clientReport (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,108] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[33mschema-registry_1  |[0m 	at io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain.main(SchemaRegistryMain.java:43)
[35mzookeeper_1        |[0m [2019-11-18 22:10:31,550] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:create cxid:0x175 zxid:0x152 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,111] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[35mzookeeper_1        |[0m [2019-11-18 22:10:31,565] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:create cxid:0x17d zxid:0x155 txntype:-1 reqpath:n/a Error Path:/brokers/topics/mysimbdp-clientReport/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/mysimbdp-clientReport/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[35mzookeeper_1        |[0m [2019-11-18 22:10:31,566] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:create cxid:0x17e zxid:0x156 txntype:-1 reqpath:n/a Error Path:/brokers/topics/mysimbdp-clientReport/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/mysimbdp-clientReport/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,111] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[35mzookeeper_1        |[0m [2019-11-18 22:43:12,400] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:setData cxid:0x190 zxid:0x15a txntype:-1 reqpath:n/a Error Path:/config/topics/spark.out Error:KeeperErrorCode = NoNode for /config/topics/spark.out (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 17:27:54,113] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-18 22:43:12,403] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:create cxid:0x191 zxid:0x15b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 17:27:54,114] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-18 22:43:12,421] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:create cxid:0x199 zxid:0x15e txntype:-1 reqpath:n/a Error Path:/brokers/topics/spark.out/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/spark.out/partitions/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 17:27:54,116] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-18 22:43:12,423] INFO Got user-level KeeperException when processing sessionid:0x16e80785b850000 type:create cxid:0x19a zxid:0x15f txntype:-1 reqpath:n/a Error Path:/brokers/topics/spark.out/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/spark.out/partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 17:27:54,117] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/zookeeper.properties
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 17:27:54,120] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for id with value from environment variable zk_id
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 17:27:54,120] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for maxClientCnxns with value from environment variable zk_maxClientCnxns
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 17:27:54,122] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for initLimit with value from environment variable zk_initLimit
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 17:27:54,123] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for DATA.DIR with value from environment variable ZK_DATA_DIR
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for syncLimit with value from environment variable zk_syncLimit
[32mkafka_1            |[0m [2019-11-18 17:27:54,125] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for clientPort with value from environment variable zk_clientPort
[32mkafka_1            |[0m [2019-11-18 17:27:54,126] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for dataDir with value from environment variable zk_dataDir
[32mkafka_1            |[0m [2019-11-18 17:27:54,128] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for tickTime with value from environment variable zk_tickTime
[32mkafka_1            |[0m [2019-11-18 17:27:54,128] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/zookeeper.properties
[32mkafka_1            |[0m [2019-11-18 17:27:54,131] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[35mzookeeper_1        |[0m [2019-11-19 15:24:04,975] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[32mkafka_1            |[0m [2019-11-18 17:27:54,131] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[35mzookeeper_1        |[0m [2019-11-19 15:24:04,979] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[32mkafka_1            |[0m [2019-11-18 17:27:54,133] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[35mzookeeper_1        |[0m [2019-11-19 15:24:04,979] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[32mkafka_1            |[0m [2019-11-18 17:27:54,134] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[35mzookeeper_1        |[0m [2019-11-19 15:24:04,979] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[32mkafka_1            |[0m [2019-11-18 17:27:54,136] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:04,979] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 17:27:54,136] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:04,998] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 17:27:54,139] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 17:27:54,139] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:04,999] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-18 17:27:54,141] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,010] INFO Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,141] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,010] INFO Server environment:host.name=rohit-X406UAR (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,144] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,010] INFO Server environment:java.version=1.8.0_91 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,144] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,104] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,010] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,147] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,105] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,011] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,148] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,105] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,011] INFO Server environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,151] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,105] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,012] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,151] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,105] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,012] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,153] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,105] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,012] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,154] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,012] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,114] INFO Verifying properties (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-18 17:27:54,156] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,012] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,116] INFO Property group.id is overridden to  (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-18 17:27:54,156] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,012] INFO Server environment:os.version=5.0.0-36-generic (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,116] WARN Property id is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m [2019-11-18 17:27:54,159] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,012] INFO Server environment:user.name=confluent (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,116] WARN Property port is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m [2019-11-18 17:27:54,159] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,013] INFO Server environment:user.home=/home/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,117] WARN Property schema.registry.url is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m [2019-11-18 17:27:54,161] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,013] INFO Server environment:user.dir=/ (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,117] INFO Property zookeeper.connect is overridden to  (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-18 17:27:54,162] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,021] INFO tickTime set to 2000 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,120] INFO KafkaAvroDeserializerConfig values: 
[32mkafka_1            |[0m [2019-11-18 17:27:54,164] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,021] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m [2019-11-18 17:27:54,164] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,021] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m [2019-11-18 17:27:54,167] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,037] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	specific.avro.reader = false
[32mkafka_1            |[0m [2019-11-18 17:27:54,167] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,544] INFO Accepted socket connection from /127.0.0.1:57294 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 17:27:54,169] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,602] INFO Client attempting to establish new session at /127.0.0.1:57294 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,122] INFO KafkaJsonDecoderConfig values: 
[32mkafka_1            |[0m [2019-11-18 17:27:54,169] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,603] INFO Creating new log file: log.163 (org.apache.zookeeper.server.persistence.FileTxnLog)
[36mrest-proxy_1       |[0m 	json.fail.unknown.properties = true
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,613] INFO Established session 0x16e84437a690000 with negotiated timeout 6000 for client /127.0.0.1:57294 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,172] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonDecoderConfig:135)
[32mkafka_1            |[0m [2019-11-18 17:27:54,172] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,820] INFO Accepted socket connection from /127.0.0.1:57296 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,146] INFO Logging initialized @911ms (org.eclipse.jetty.util.log:186)
[32mkafka_1            |[0m [2019-11-18 17:27:54,174] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,822] INFO Client attempting to establish new session at /127.0.0.1:57296 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,174] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,156] WARN DEPRECATION warning: `listeners` configuration is not configured. Falling back to the deprecated `port` configuration. (io.confluent.rest.Application:248)
[35mzookeeper_1        |[0m [2019-11-19 15:24:05,824] INFO Established session 0x16e84437a690001 with negotiated timeout 30000 for client /127.0.0.1:57296 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,177] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,156] INFO Adding listener: http://0.0.0.0:8082 (io.confluent.rest.Application:137)
[35mzookeeper_1        |[0m [2019-11-19 15:24:06,381] INFO Got user-level KeeperException when processing sessionid:0x16e84437a690000 type:create cxid:0x18 zxid:0x165 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,177] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,211] INFO jetty-9.2.12.v20150709 (org.eclipse.jetty.server.Server:327)
[35mzookeeper_1        |[0m [2019-11-19 15:24:06,382] INFO Got user-level KeeperException when processing sessionid:0x16e84437a690000 type:create cxid:0x19 zxid:0x166 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,180] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,657] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version:27)
[35mzookeeper_1        |[0m [2019-11-19 15:24:06,382] INFO Got user-level KeeperException when processing sessionid:0x16e84437a690000 type:create cxid:0x1a zxid:0x167 txntype:-1 reqpath:n/a Error Path:/brokers/ids/0 Error:KeeperErrorCode = NodeExists for /brokers/ids/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,180] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,803] INFO Started o.e.j.s.ServletContextHandler@26f96b85{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[35mzookeeper_1        |[0m [2019-11-19 15:24:09,053] INFO Processed session termination for sessionid: 0x16e84437a690000 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,187] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,809] INFO Started NetworkTrafficServerConnector@7e7f0f0a{HTTP/1.1}{0.0.0.0:8082} (org.eclipse.jetty.server.NetworkTrafficServerConnector:266)
[35mzookeeper_1        |[0m [2019-11-19 15:24:09,058] INFO Closed socket connection for client /127.0.0.1:57294 which had sessionid 0x16e84437a690000 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:54,187] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,810] INFO Started @1575ms (org.eclipse.jetty.server.Server:379)
[35mzookeeper_1        |[0m [2019-11-19 15:24:12,001] INFO Expiring session 0x16e80785b850000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,188] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:28:03,810] INFO Server started, listening for requests... (io.confluent.kafkarest.KafkaRestMain:38)
[35mzookeeper_1        |[0m [2019-11-19 15:24:12,002] INFO Processed session termination for sessionid: 0x16e80785b850000 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,188] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 17:29:19,061] INFO 127.0.0.1 - - [18/Nov/2019:17:29:18 +0000] "GET / HTTP/1.1" 200 2  81 (io.confluent.rest-utils.requests:77)
[35mzookeeper_1        |[0m [2019-11-19 15:24:16,077] INFO Accepted socket connection from /127.0.0.1:57486 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 17:27:54,189] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 19:43:12,211] INFO Stopped NetworkTrafficServerConnector@7e7f0f0a{HTTP/1.1}{0.0.0.0:8082} (org.eclipse.jetty.server.NetworkTrafficServerConnector:306)
[35mzookeeper_1        |[0m [2019-11-19 15:24:16,080] INFO Client attempting to establish new session at /127.0.0.1:57486 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,189] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 19:43:12,231] INFO Stopped o.e.j.s.ServletContextHandler@26f96b85{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:865)
[35mzookeeper_1        |[0m [2019-11-19 15:24:16,083] INFO Established session 0x16e84437a690002 with negotiated timeout 30000 for client /127.0.0.1:57486 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,190] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 19:43:12,234] INFO Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[35mzookeeper_1        |[0m [2019-11-19 15:24:16,627] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:54,190] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m EndOfStreamException: Unable to read additional data from client sessionid 0x16e84437a690002, likely client has closed socket
[36mrest-proxy_1       |[0m [2019-11-18 19:43:12,236] INFO Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[32mkafka_1            |[0m [2019-11-18 17:27:54,191] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
[36mrest-proxy_1       |[0m [2019-11-18 19:43:12,238] INFO Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[32mkafka_1            |[0m [2019-11-18 17:27:54,191] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
[36mrest-proxy_1       |[0m [2019-11-18 19:43:12,239] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread:82)
[32mkafka_1            |[0m [2019-11-18 17:27:54,193] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m 	at java.lang.Thread.run(Thread.java:745)
[36mrest-proxy_1       |[0m [2019-11-18 19:43:12,244] INFO Session: 0x16e7f8e6dbc0004 closed (org.apache.zookeeper.ZooKeeper:679)
[32mkafka_1            |[0m [2019-11-18 17:27:54,193] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:16,634] INFO Closed socket connection for client /127.0.0.1:57486 which had sessionid 0x16e84437a690002 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 19:43:12,245] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn:511)
[32mkafka_1            |[0m [2019-11-18 17:27:54,194] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:36,001] INFO Expiring session 0x16e80785b850002, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka-rest/kafka-rest.properties
[32mkafka_1            |[0m [2019-11-18 17:27:54,194] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:36,001] INFO Processed session termination for sessionid: 0x16e80785b850002 (org.apache.zookeeper.server.PrepRequestProcessor)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable RP_ZOOKEEPER_CONNECT
[32mkafka_1            |[0m [2019-11-18 17:27:54,195] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:24:46,901] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for schema.registry.url with value from environment variable RP_SCHEMA_REGISTRY_URL
[35mzookeeper_1        |[0m EndOfStreamException: Unable to read additional data from client sessionid 0x16e84437a690001, likely client has closed socket
[32mkafka_1            |[0m [2019-11-18 17:27:54,196] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka-rest/kafka-rest.properties
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
[32mkafka_1            |[0m [2019-11-18 17:27:54,209] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 9 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m SLF4J: Class path contains multiple SLF4J bindings.
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
[32mkafka_1            |[0m [2019-11-18 17:27:54,209] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[35mzookeeper_1        |[0m 	at java.lang.Thread.run(Thread.java:745)
[32mkafka_1            |[0m [2019-11-18 17:27:54,211] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/kafka-rest/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[35mzookeeper_1        |[0m [2019-11-19 15:24:46,904] INFO Closed socket connection for client /127.0.0.1:57296 which had sessionid 0x16e84437a690001 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 17:27:54,211] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[35mzookeeper_1        |[0m [2019-11-19 15:24:48,000] INFO Expiring session 0x16e84437a690002, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,212] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[35mzookeeper_1        |[0m [2019-11-19 15:24:48,001] INFO Processed session termination for sessionid: 0x16e84437a690002 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,212] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:50,863] INFO KafkaRestConfig values: 
[35mzookeeper_1        |[0m [2019-11-19 15:25:18,000] INFO Expiring session 0x16e84437a690001, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 17:27:54,214] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.timeout.ms = 1000
[35mzookeeper_1        |[0m [2019-11-19 15:25:18,001] INFO Processed session termination for sessionid: 0x16e84437a690001 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 17:27:54,214] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/zookeeper.properties
[32mkafka_1            |[0m [2019-11-18 17:27:54,215] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.client.auth = false
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for id with value from environment variable zk_id
[32mkafka_1            |[0m [2019-11-18 17:37:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	consumer.iterator.timeout.ms = 1
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for maxClientCnxns with value from environment variable zk_maxClientCnxns
[32mkafka_1            |[0m [2019-11-18 17:47:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	response.mediatype.default = application/vnd.kafka.v1+json
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for initLimit with value from environment variable zk_initLimit
[32mkafka_1            |[0m [2019-11-18 17:56:23,993] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for DATA.DIR with value from environment variable ZK_DATA_DIR
[32mkafka_1            |[0m [2019-11-18 17:56:23,994] INFO [KafkaApi-0] Auto creation of topic mysimbdp with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for syncLimit with value from environment variable zk_syncLimit
[32mkafka_1            |[0m [2019-11-18 17:56:24,334] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [mysimbdp,0] (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = 
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for clientPort with value from environment variable zk_clientPort
[32mkafka_1            |[0m [2019-11-18 17:56:24,336] INFO Completed load of log mysimbdp-0 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	schema.registry.url = http://localhost:8081
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for dataDir with value from environment variable zk_dataDir
[32mkafka_1            |[0m [2019-11-18 17:56:24,336] INFO Created log for partition [mysimbdp,0] in /var/lib/kafka with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	metrics.jmx.prefix = kafka.rest
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for tickTime with value from environment variable zk_tickTime
[32mkafka_1            |[0m [2019-11-18 17:56:24,337] INFO Partition [mysimbdp,0] on broker 0: No checkpointed highwatermark is found for partition [mysimbdp,0] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	request.logger.name = io.confluent.rest-utils.requests
[35mzookeeper_1        |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/zookeeper.properties
[32mkafka_1            |[0m [2019-11-18 17:57:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.key.password = 
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,093] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,095] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,095] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[32mkafka_1            |[0m [2019-11-18 18:07:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = 
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,095] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[36mrest-proxy_1       |[0m 	id = 1
[32mkafka_1            |[0m [2019-11-18 18:17:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,095] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[36mrest-proxy_1       |[0m 	host.name = 
[32mkafka_1            |[0m [2019-11-18 18:27:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,125] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[36mrest-proxy_1       |[0m 	consumer.request.max.bytes = 67108864
[32mkafka_1            |[0m [2019-11-18 18:37:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,125] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 18:47:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,135] INFO Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = 
[32mkafka_1            |[0m [2019-11-18 18:57:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	consumer.threads = 1
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,135] INFO Server environment:host.name=rohit-X406UAR (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:07:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,135] INFO Server environment:java.version=1.8.0_91 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:17:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	debug = false
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,135] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:27:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,135] INFO Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	listeners = []
[32mkafka_1            |[0m [2019-11-18 19:37:52,283] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 19:43:13,567] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,136] INFO Server environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:13,568] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	ssl.provider = 
[32mkafka_1            |[0m [2019-11-18 19:43:13,584] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,137] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:13,586] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = []
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,137] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:13,590] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[36mrest-proxy_1       |[0m 	producer.threads = 5
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,137] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:13,590] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[36mrest-proxy_1       |[0m 	shutdown.graceful.ms = 1000
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,137] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:13,592] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = 
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,138] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:13,593] INFO [ThrottledRequestReaper-Produce], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	response.mediatype.preferred = [application/vnd.kafka.v1+json, application/vnd.kafka+json, application/json]
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,138] INFO Server environment:os.version=5.0.0-36-generic (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:13,879] INFO [ThrottledRequestReaper-Produce], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	consumer.request.timeout.ms = 1000
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,138] INFO Server environment:user.name=confluent (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:13,879] INFO [ThrottledRequestReaper-Fetch], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = []
[32mkafka_1            |[0m [2019-11-18 19:43:13,881] INFO [ThrottledRequestReaper-Produce], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,138] INFO Server environment:user.home=/home/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 19:43:14,878] INFO [ThrottledRequestReaper-Fetch], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,138] INFO Server environment:user.dir=/ (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	consumer.instance.timeout.ms = 300000
[32mkafka_1            |[0m [2019-11-18 19:43:14,878] INFO [ThrottledRequestReaper-Fetch], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,145] INFO tickTime set to 2000 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:14,879] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,146] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	access.control.allow.methods = 
[32mkafka_1            |[0m [2019-11-18 19:43:14,882] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,146] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	consumer.iterator.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-18 19:43:14,882] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,158] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	access.control.allow.origin = 
[32mkafka_1            |[0m [2019-11-18 19:43:14,886] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[35mzookeeper_1        |[0m [2019-11-19 15:26:32,967] INFO Accepted socket connection from /127.0.0.1:58130 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = 
[32mkafka_1            |[0m [2019-11-18 19:43:14,886] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:33,030] INFO Client attempting to establish new session at /127.0.0.1:58130 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:15,027] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:33,032] INFO Creating new log file: log.16e (org.apache.zookeeper.server.persistence.FileTxnLog)
[32mkafka_1            |[0m [2019-11-18 19:43:15,027] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:33,038] INFO Established session 0x16e8445b9100000 with negotiated timeout 6000 for client /127.0.0.1:58130 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = 
[32mkafka_1            |[0m [2019-11-18 19:43:15,028] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:33,272] INFO Accepted socket connection from /127.0.0.1:58132 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = 
[32mkafka_1            |[0m [2019-11-18 19:43:15,180] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:33,274] INFO Client attempting to establish new session at /127.0.0.1:58132 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	zookeeper.connect = localhost:2181
[32mkafka_1            |[0m [2019-11-18 19:43:15,180] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:33,278] INFO Established session 0x16e8445b9100001 with negotiated timeout 30000 for client /127.0.0.1:58132 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m 	port = 8082
[32mkafka_1            |[0m [2019-11-18 19:43:15,186] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[35mzookeeper_1        |[0m [2019-11-19 15:26:33,813] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 19:43:15,187] INFO Shutting down. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.size.max = 25
[35mzookeeper_1        |[0m EndOfStreamException: Unable to read additional data from client sessionid 0x16e8445b9100001, likely client has closed socket
[32mkafka_1            |[0m [2019-11-18 19:43:15,225] INFO Shutdown complete. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m  (io.confluent.kafkarest.KafkaRestConfig:135)
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
[32mkafka_1            |[0m [2019-11-18 19:43:15,226] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,056] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread:64)
[35mzookeeper_1        |[0m 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
[32mkafka_1            |[0m [2019-11-18 19:43:15,226] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,060] INFO Client environment:zookeeper.version=3.4.3-1240972, built on 02/06/2012 10:48 GMT (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m 	at java.lang.Thread.run(Thread.java:745)
[32mkafka_1            |[0m [2019-11-18 19:43:15,380] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,060] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-19 15:26:33,816] INFO Closed socket connection for client /127.0.0.1:58132 which had sessionid 0x16e8445b9100001 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m [2019-11-18 19:43:15,380] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,060] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-19 15:26:34,292] INFO Got user-level KeeperException when processing sessionid:0x16e8445b9100000 type:delete cxid:0xd3 zxid:0x172 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 19:43:15,381] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,060] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-19 15:26:34,366] INFO Got user-level KeeperException when processing sessionid:0x16e8445b9100000 type:create cxid:0xda zxid:0x173 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 19:43:15,581] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,060] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-19 15:26:34,367] INFO Got user-level KeeperException when processing sessionid:0x16e8445b9100000 type:create cxid:0xdb zxid:0x174 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 19:43:15,581] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[35mzookeeper_1        |[0m [2019-11-19 15:26:43,665] INFO Accepted socket connection from /127.0.0.1:58146 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mkafka_1            |[0m [2019-11-18 19:43:15,584] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.GroupCoordinator)
[35mzookeeper_1        |[0m [2019-11-19 15:26:43,668] INFO Client attempting to establish new session at /127.0.0.1:58146 (org.apache.zookeeper.server.ZooKeeperServer)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,061] INFO Client environment:java.class.path=:/usr/bin/../target/kafka-rest-*-development/share/java/kafka-rest/*:/usr/bin/../share/java/confluent-common/slf4j-api-1.7.6.jar:/usr/bin/../share/java/confluent-common/common-utils-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-config-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-metrics-3.0.0.jar:/usr/bin/../share/java/confluent-common/jline-0.9.94.jar:/usr/bin/../share/java/confluent-common/zkclient-0.5.jar:/usr/bin/../share/java/confluent-common/netty-3.2.2.Final.jar:/usr/bin/../share/java/confluent-common/zookeeper-3.4.3.jar:/usr/bin/../share/java/confluent-common/log4j-1.2.17.jar:/usr/bin/../share/java/confluent-common/slf4j-log4j12-1.7.6.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-json-provider-2.5.4.jar:/usr/bin/../share/java/rest-utils/jetty-server-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jboss-logging-3.1.3.GA.jar:/usr/bin/../share/java/rest-utils/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/rest-utils/javassist-3.18.1-GA.jar:/usr/bin/../share/java/rest-utils/jersey-common-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-test-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-provider-jetty-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-security-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-util-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.el-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-http-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-base-2.5.4.jar:/usr/bin/../share/java/rest-utils/hk2-utils-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.el-api-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-io-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.inject-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.annotation-api-1.2.jar:/usr/bin/../share/java/rest-utils/junit-4.12.jar:/usr/bin/../share/java/rest-utils/rest-utils-examples-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-bean-validation-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-continuation-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/classmate-1.0.0.jar:/usr/bin/../share/java/rest-utils/hamcrest-core-1.3.jar:/usr/bin/../share/java/rest-utils/hibernate-validator-5.1.2.Final.jar:/usr/bin/../share/java/rest-utils/jetty-servlets-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jersey-client-2.19.jar:/usr/bin/../share/java/rest-utils/hk2-locator-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/aopalliance-repackaged-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-container-jetty-http-2.19.jar:/usr/bin/../share/java/rest-utils/jackson-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-core-2.19.jar:/usr/bin/../share/java/rest-utils/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/rest-utils/jackson-databind-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-server-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-servlet-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/hk2-api-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jackson-core-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-media-jaxb-2.19.jar:/usr/bin/../share/java/rest-utils/jersey-guava-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-3.0.0.jar:/usr/bin/../share/java/rest-utils/jackson-module-jaxb-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/asm-debug-all-5.0.3.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-core-2.19.jar:/usr/bin/../share/java/rest-utils/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-2.19.jar:/usr/bin/../share/java/kafka-rest/lz4-1.3.0.jar:/usr/bin/../share/java/kafka-rest/paranamer-2.3.jar:/usr/bin/../share/java/kafka-rest/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka-rest/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka-rest/netty-3.7.0.Final.jar:/usr/bin/../share/java/kafka-rest/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka-rest/kafka-json-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/zkclient-0.8.jar:/usr/bin/../share/java/kafka-rest/kafka-schema-registry-client-3.0.0.jar:/usr/bin/../share/java/kafka-rest/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka-rest/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka-rest/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka-rest/kafka-rest-3.0.0.jar:/usr/bin/../share/java/kafka-rest/xz-1.0.jar:/usr/bin/../share/java/kafka-rest/log4j-1.2.15.jar:/usr/bin/../share/java/kafka-rest/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/activation-1.1.jar:/usr/bin/../share/java/kafka-rest/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka-rest/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/avro-1.7.7.jar:/usr/bin/../share/java/kafka-rest/jline-0.9.94.jar:/usr/bin/../share/java/kafka-rest/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka-rest/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka-rest/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/kafka-avro-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/mail-1.4.jar (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-18 19:43:15,599] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[35mzookeeper_1        |[0m [2019-11-19 15:26:43,671] INFO Established session 0x16e8445b9100002 with negotiated timeout 30000 for client /127.0.0.1:58146 (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:15,602] INFO Session: 0x16e7f8e6dbc0000 closed (org.apache.zookeeper.ZooKeeper)
[35mzookeeper_1        |[0m [2019-11-19 15:27:04,001] INFO Expiring session 0x16e8445b9100001, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[32mkafka_1            |[0m [2019-11-18 19:43:15,602] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,061] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-19 15:27:04,002] INFO Processed session termination for sessionid: 0x16e8445b9100001 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m [2019-11-18 19:43:15,603] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,061] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-19 18:50:46,073] INFO Processed session termination for sessionid: 0x16e8445b9100002 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/server.properties
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,061] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-19 18:50:46,081] INFO Closed socket connection for client /127.0.0.1:58146 which had sessionid 0x16e8445b9100002 (org.apache.zookeeper.server.NIOServerCnxn)
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable KAFKA_ZOOKEEPER_CONNECT
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,062] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper:98)
[35mzookeeper_1        |[0m [2019-11-19 18:50:48,938] INFO Processed session termination for sessionid: 0x16e8445b9100000 (org.apache.zookeeper.server.PrepRequestProcessor)
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for log.dirs with value from environment variable KAFKA_LOG_DIRS
[35mzookeeper_1        |[0m [2019-11-19 18:50:48,942] INFO Closed socket connection for client /127.0.0.1:58130 which had sessionid 0x16e8445b9100000 (org.apache.zookeeper.server.NIOServerCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,062] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/server.properties
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,062] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-18 21:42:40,344] INFO KafkaConfig values: 
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,062] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	advertised.host.name = null
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,062] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	metric.reporters = []
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,063] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	quota.producer.default = 9223372036854775807
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,063] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@75c072cb (org.apache.zookeeper.ZooKeeper:433)
[32mkafka_1            |[0m 	offsets.topic.num.partitions = 50
[32mkafka_1            |[0m 	log.flush.interval.messages = 9223372036854775807
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,072] INFO Opening socket connection to server /127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn:933)
[32mkafka_1            |[0m 	auto.create.topics.enable = true
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,073] INFO Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration. (org.apache.zookeeper.client.ZooKeeperSaslClient:125)
[32mkafka_1            |[0m 	controller.socket.timeout.ms = 30000
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,115] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn:846)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,122] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e8077b7d30002, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn:1175)
[32mkafka_1            |[0m 	log.flush.interval.ms = null
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,123] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient:641)
[32mkafka_1            |[0m 	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,381] INFO ProducerConfig values: 
[32mkafka_1            |[0m 	replica.socket.receive.buffer.bytes = 65536
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	min.insync.replicas = 1
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m 	replica.fetch.wait.max.ms = 500
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m 	num.recovery.threads.per.data.dir = 1
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m 	default.replication.factor = 1
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	ssl.truststore.password = null
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	log.preallocate = false
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	replica.socket.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m 	message.max.bytes = 1000012
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	num.io.threads = 8
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	offsets.commit.required.acks = -1
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m 	delete.topic.enable = true
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m 	quota.window.size.seconds = 1
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m 	ssl.truststore.type = JKS
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m 	offsets.commit.timeout.ms = 5000
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m 	quota.window.num = 11
[32mkafka_1            |[0m 	zookeeper.connect = localhost:2181
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m 	authorizer.class.name = 
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m 	num.replica.fetchers = 1
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m 	log.retention.ms = null
[36mrest-proxy_1       |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m 	log.roll.jitter.hours = 0
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m 	log.cleaner.enable = true
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m 	offsets.load.buffer.size = 5242880
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m 	log.cleaner.delete.retention.ms = 86400000
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m 	ssl.client.auth = none
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m 	controlled.shutdown.max.retries = 3
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m 	queued.max.requests = 500
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m 	offsets.topic.replication.factor = 3
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m 	log.cleaner.threads = 1
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	sasl.kerberos.service.name = null
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m 	socket.request.max.bytes = 104857600
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m 	ssl.trustmanager.algorithm = PKIX
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m 	zookeeper.session.timeout.ms = 6000
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m 	log.retention.bytes = -1
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m 	log.message.timestamp.type = CreateTime
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m 	zookeeper.set.acl = false
[36mrest-proxy_1       |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m 	connections.max.idle.ms = 600000
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m 	offsets.retention.minutes = 1440
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m 	replica.fetch.backoff.ms = 1000
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m 	inter.broker.protocol.version = 0.10.0-IV1
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m 	log.retention.hours = 168
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m 	num.partitions = 1
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,410] INFO ProducerConfig values: 
[32mkafka_1            |[0m 	broker.id.generation.enable = true
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	listeners = null
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m 	ssl.provider = null
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m 	log.roll.ms = null
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	ssl.cipher.suites = null
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m 	log.index.size.max.bytes = 10485760
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m 	replica.fetch.max.bytes = 1048576
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	advertised.port = null
[36mrest-proxy_1       |[0m 	client.id = producer-1
[32mkafka_1            |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m 	log.cleaner.io.buffer.size = 524288
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	zookeeper.connection.timeout.ms = 6000
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m 	log.roll.hours = 168
[32mkafka_1            |[0m 	log.cleanup.policy = delete
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m 	host.name = 
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m 	log.roll.jitter.ms = null
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m 	max.connections.per.ip = 2147483647
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m 	offsets.topic.segment.bytes = 104857600
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m 	background.threads = 10
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m 	quota.consumer.default = 9223372036854775807
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m 	request.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m 	log.message.format.version = 0.10.0-IV1
[36mrest-proxy_1       |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m 	log.index.interval.bytes = 4096
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m 	log.dir = /tmp/kafka-logs
[32mkafka_1            |[0m 	log.segment.bytes = 1073741824
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m 	log.cleaner.backoff.ms = 15000
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m 	offset.metadata.max.bytes = 4096
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m 	ssl.truststore.location = null
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m 	group.max.session.timeout.ms = 300000
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m 	ssl.keystore.password = null
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m 	zookeeper.sync.time.ms = 2000
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m 	port = 9092
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	log.retention.minutes = null
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	log.segment.delete.delay.ms = 60000
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m 	log.dirs = /var/lib/kafka
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m 	controlled.shutdown.enable = true
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m 	compression.type = producer
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m 	max.connections.per.ip.overrides = 
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mrest-proxy_1       |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka_1            |[0m 	auto.leader.rebalance.enable = true
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m 	leader.imbalance.check.interval.seconds = 300
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m 	replica.lag.time.max.ms = 10000
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m 	num.network.threads = 3
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m 	ssl.key.password = null
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,412] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	reserved.broker.max.id = 1000
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,412] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	metrics.num.samples = 2
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,412] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	socket.send.buffer.bytes = 102400
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,412] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	socket.receive.buffer.bytes = 102400
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,414] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m 	replica.fetch.min.bytes = 1
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,414] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[32mkafka_1            |[0m 	broker.rack = null
[32mkafka_1            |[0m 	unclean.leader.election.enable = true
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,416] INFO KafkaJsonSerializerConfig values: 
[36mrest-proxy_1       |[0m 	json.indent.output = false
[32mkafka_1            |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig:135)
[32mkafka_1            |[0m 	group.min.session.timeout.ms = 6000
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,416] INFO KafkaJsonSerializerConfig values: 
[32mkafka_1            |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36mrest-proxy_1       |[0m 	json.indent.output = false
[32mkafka_1            |[0m 	offsets.retention.check.interval.ms = 600000
[32mkafka_1            |[0m 	producer.purgatory.purge.interval.requests = 1000
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig:135)
[32mkafka_1            |[0m 	metrics.sample.window.ms = 30000
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,416] INFO ProducerConfig values: 
[32mkafka_1            |[0m 	broker.id = 0
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	offsets.topic.compression.codec = 0
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m 	log.retention.check.interval.ms = 300000
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m 	advertised.listeners = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m 	leader.imbalance.per.broker.percentage = 10
[32mkafka_1            |[0m  (kafka.server.KafkaConfig)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-18 21:42:40,379] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:42:40,379] INFO starting (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 21:42:40,384] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:40,392] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,397] INFO Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,397] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m [2019-11-18 21:42:40,397] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,397] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:40,397] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	acks = 1
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:42:40,397] INFO Client environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	retries = 0
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,398] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,398] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-18 21:42:40,398] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:40,398] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 21:42:40,398] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-18 21:42:40,398] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper)
[32mkafka_1            |[0m [2019-11-18 21:42:40,398] INFO Client environment:user.name=confluent (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-18 21:42:40,398] INFO Client environment:user.home=/home/confluent (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:40,398] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,399] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@63355449 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 21:42:40,411] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 21:42:40,414] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 21:42:40,476] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,567] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e8077b7d30000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:40,569] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 21:42:40,757] INFO Loading logs. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-18 21:42:40,785] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 21:42:40,790] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 21:42:40,792] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 21:42:40,795] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,797] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-18 21:42:40,800] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-18 21:42:40,802] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,806] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,808] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-18 21:42:40,810] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-18 21:42:40,812] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m [2019-11-18 21:42:40,815] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 21:42:40,817] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-18 21:42:40,820] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-18 21:42:40,822] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-18 21:42:40,824] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,420] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:42:40,827] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 21:42:40,829] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-18 21:42:40,831] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-18 21:42:40,833] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-18 21:42:40,835] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-18 21:42:40,837] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:42:40,846] INFO Completed load of log mysimbdp-0 with log end offset 109 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 21:42:40,849] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:40,851] INFO Completed load of log _schemas-0 with log end offset 1 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,854] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,856] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	client.id = producer-2
[32mkafka_1            |[0m [2019-11-18 21:42:40,860] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,862] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:40,865] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-18 21:42:40,867] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 21:42:40,870] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:42:40,872] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-18 21:42:40,874] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,876] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,878] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m [2019-11-18 21:42:40,881] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-18 21:42:40,884] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-18 21:42:40,886] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:40,888] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 21:42:40,890] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-18 21:42:40,892] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:40,894] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,896] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 21:42:40,898] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 21:42:40,900] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 21:42:40,903] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:40,905] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 21:42:40,907] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 21:42:40,909] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 21:42:40,911] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 21:42:40,913] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,915] INFO Logs loading complete. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-18 21:42:40,980] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-18 21:42:40,981] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-18 21:42:41,024] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-18 21:42:41,026] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m [2019-11-18 21:42:41,037] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 21:42:41,038] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:41,067] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-18 21:42:41,075] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-18 21:42:41,075] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-18 21:42:41,627] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,420] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:42:41,627] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,420] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:42:41,628] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,420] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:42:41,657] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,420] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,421] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m [2019-11-18 21:42:41,657] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,421] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[32mkafka_1            |[0m [2019-11-18 21:42:41,658] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,536] INFO KafkaAvroSerializerConfig values: 
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m [2019-11-18 21:42:41,674] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m [2019-11-18 21:42:41,674] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 21:42:41,685] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,541] INFO KafkaAvroSerializerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:42:41,701] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m [2019-11-18 21:42:41,704] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m [2019-11-18 21:42:41,705] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(rohit-X406UAR,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 21:42:41,712] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,541] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:42:41,712] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 21:42:41,713] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-18 21:42:41,848] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[mysimbdp,0],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[_schemas,0],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-18 21:42:42,078] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-18 21:42:42,085] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-18 21:42:42,085] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:42:42,088] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 21:42:42,089] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:42,091] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,092] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,094] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m [2019-11-18 21:42:42,095] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,097] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:42,097] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-18 21:42:42,100] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 21:42:42,100] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:42:42,102] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-18 21:42:42,102] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,105] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m [2019-11-18 21:42:42,105] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-18 21:42:42,108] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:42,108] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 21:42:42,111] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-18 21:42:42,111] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:42,113] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 21:42:42,113] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 21:42:42,116] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 21:42:42,116] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 21:42:42,119] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,119] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:42,121] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 21:42:42,121] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 21:42:42,124] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 21:42:42,124] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 21:42:42,127] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,127] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-18 21:42:42,130] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,130] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-18 21:42:42,132] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-18 21:42:42,132] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 21:42:42,135] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 21:42:42,135] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:42,138] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-18 21:42:42,138] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-18 21:42:42,141] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-18 21:42:42,141] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,545] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:42:42,144] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 21:42:42,144] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-18 21:42:42,147] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-18 21:42:42,147] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:42:42,150] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 21:42:42,150] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:42,153] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,153] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,156] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	client.id = producer-3
[32mkafka_1            |[0m [2019-11-18 21:42:42,156] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:42:42,158] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:42,159] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	acks = 1
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 21:42:42,159] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[mysimbdp,0],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[_schemas,0],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-18 21:42:42,161] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,161] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,164] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m [2019-11-18 21:42:42,164] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	compression.type = none
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:42,167] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 21:42:42,167] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-18 21:42:42,169] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:42,170] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 21:42:42,172] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,172] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 21:42:42,175] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 21:42:42,176] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 21:42:42,178] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,178] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 21:42:42,181] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 21:42:42,181] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 21:42:42,184] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,184] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-18 21:42:42,187] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-18 21:42:42,187] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,194] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-18 21:42:42,194] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-18 21:42:42,195] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-18 21:42:42,195] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 21:42:42,195] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 21:42:42,195] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:42:42,196] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-18 21:42:42,196] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-18 21:42:42,197] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,545] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,545] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:42:42,197] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,545] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:42:42,197] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,545] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:42:42,197] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,546] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m [2019-11-18 21:42:42,198] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,546] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[32mkafka_1            |[0m [2019-11-18 21:42:42,198] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,556] INFO Verifying properties (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-18 21:42:42,199] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,558] INFO Property group.id is overridden to  (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-18 21:42:42,199] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,558] WARN Property id is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m [2019-11-18 21:42:42,200] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,558] WARN Property port is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m [2019-11-18 21:42:42,200] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,559] WARN Property schema.registry.url is not valid (kafka.utils.VerifiableProperties:83)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,559] INFO Property zookeeper.connect is overridden to  (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-18 21:42:42,208] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,562] INFO KafkaAvroDeserializerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:42:42,208] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m [2019-11-18 21:42:42,209] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m [2019-11-18 21:42:42,209] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	specific.avro.reader = false
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 21:42:42,210] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,564] INFO KafkaJsonDecoderConfig values: 
[36mrest-proxy_1       |[0m 	json.fail.unknown.properties = true
[32mkafka_1            |[0m [2019-11-18 21:42:42,210] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonDecoderConfig:135)
[32mkafka_1            |[0m [2019-11-18 21:42:42,211] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,583] INFO Logging initialized @945ms (org.eclipse.jetty.util.log:186)
[32mkafka_1            |[0m [2019-11-18 21:42:59,047] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,592] WARN DEPRECATION warning: `listeners` configuration is not configured. Falling back to the deprecated `port` configuration. (io.confluent.rest.Application:248)
[32mkafka_1            |[0m [2019-11-18 21:42:59,047] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,592] INFO Adding listener: http://0.0.0.0:8082 (io.confluent.rest.Application:137)
[32mkafka_1            |[0m [2019-11-18 21:42:59,062] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:51,639] INFO jetty-9.2.12.v20150709 (org.eclipse.jetty.server.Server:327)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:52,057] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version:27)
[32mkafka_1            |[0m [2019-11-18 21:42:59,063] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:52,201] INFO Started o.e.j.s.ServletContextHandler@26f96b85{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[32mkafka_1            |[0m [2019-11-18 21:42:59,067] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:52,207] INFO Started NetworkTrafficServerConnector@7e7f0f0a{HTTP/1.1}{0.0.0.0:8082} (org.eclipse.jetty.server.NetworkTrafficServerConnector:266)
[32mkafka_1            |[0m [2019-11-18 21:42:59,068] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:52,219] INFO Started @1581ms (org.eclipse.jetty.server.Server:379)
[32mkafka_1            |[0m [2019-11-18 21:42:59,069] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[36mrest-proxy_1       |[0m [2019-11-18 21:42:52,220] INFO Server started, listening for requests... (io.confluent.kafkarest.KafkaRestMain:38)
[32mkafka_1            |[0m [2019-11-18 21:42:59,071] INFO [ThrottledRequestReaper-Produce], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka-rest/kafka-rest.properties
[32mkafka_1            |[0m [2019-11-18 21:42:59,678] INFO [ThrottledRequestReaper-Produce], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable RP_ZOOKEEPER_CONNECT
[32mkafka_1            |[0m [2019-11-18 21:42:59,678] INFO [ThrottledRequestReaper-Produce], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for schema.registry.url with value from environment variable RP_SCHEMA_REGISTRY_URL
[32mkafka_1            |[0m [2019-11-18 21:42:59,678] INFO [ThrottledRequestReaper-Fetch], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka-rest/kafka-rest.properties
[32mkafka_1            |[0m [2019-11-18 21:43:00,678] INFO [ThrottledRequestReaper-Fetch], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m SLF4J: Class path contains multiple SLF4J bindings.
[32mkafka_1            |[0m [2019-11-18 21:43:00,678] INFO [ThrottledRequestReaper-Fetch], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-18 21:43:00,679] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[32mkafka_1            |[0m [2019-11-18 21:43:00,682] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m [2019-11-18 21:43:00,683] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[32mkafka_1            |[0m [2019-11-18 21:43:00,684] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/kafka-rest/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m [2019-11-18 21:43:00,684] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[32mkafka_1            |[0m [2019-11-18 21:43:00,854] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[32mkafka_1            |[0m [2019-11-18 21:43:00,854] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:32,832] INFO KafkaRestConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:43:00,854] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.timeout.ms = 1000
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 21:43:01,054] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.client.auth = false
[32mkafka_1            |[0m [2019-11-18 21:43:01,054] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	consumer.iterator.timeout.ms = 1
[32mkafka_1            |[0m [2019-11-18 21:43:01,061] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[36mrest-proxy_1       |[0m 	response.mediatype.default = application/vnd.kafka.v1+json
[32mkafka_1            |[0m [2019-11-18 21:43:01,061] INFO Shutting down. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:43:01,083] INFO Shutdown complete. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = 
[32mkafka_1            |[0m [2019-11-18 21:43:01,083] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	schema.registry.url = http://localhost:8081
[32mkafka_1            |[0m [2019-11-18 21:43:01,083] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	metrics.jmx.prefix = kafka.rest
[32mkafka_1            |[0m [2019-11-18 21:43:01,244] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	request.logger.name = io.confluent.rest-utils.requests
[32mkafka_1            |[0m [2019-11-18 21:43:01,244] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.key.password = 
[32mkafka_1            |[0m [2019-11-18 21:43:01,244] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = 
[32mkafka_1            |[0m [2019-11-18 21:43:01,444] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	id = 1
[32mkafka_1            |[0m [2019-11-18 21:43:01,444] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	host.name = 
[32mkafka_1            |[0m [2019-11-18 21:43:01,445] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	consumer.request.max.bytes = 67108864
[32mkafka_1            |[0m [2019-11-18 21:43:01,453] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 21:43:01,456] INFO Session: 0x16e8077b7d30000 closed (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = 
[32mkafka_1            |[0m [2019-11-18 21:43:01,456] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	consumer.threads = 1
[32mkafka_1            |[0m [2019-11-18 21:43:01,457] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/server.properties
[36mrest-proxy_1       |[0m 	debug = false
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable KAFKA_ZOOKEEPER_CONNECT
[36mrest-proxy_1       |[0m 	listeners = []
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for log.dirs with value from environment variable KAFKA_LOG_DIRS
[36mrest-proxy_1       |[0m 	ssl.provider = 
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/server.properties
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = []
[32mkafka_1            |[0m [2019-11-18 21:43:22,264] INFO KafkaConfig values: 
[36mrest-proxy_1       |[0m 	producer.threads = 5
[32mkafka_1            |[0m 	advertised.host.name = null
[36mrest-proxy_1       |[0m 	shutdown.graceful.ms = 1000
[32mkafka_1            |[0m 	metric.reporters = []
[36mrest-proxy_1       |[0m 	ssl.keystore.location = 
[32mkafka_1            |[0m 	quota.producer.default = 9223372036854775807
[36mrest-proxy_1       |[0m 	response.mediatype.preferred = [application/vnd.kafka.v1+json, application/vnd.kafka+json, application/json]
[32mkafka_1            |[0m 	offsets.topic.num.partitions = 50
[36mrest-proxy_1       |[0m 	consumer.request.timeout.ms = 1000
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = []
[32mkafka_1            |[0m 	log.flush.interval.messages = 9223372036854775807
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	auto.create.topics.enable = true
[36mrest-proxy_1       |[0m 	consumer.instance.timeout.ms = 300000
[36mrest-proxy_1       |[0m 	access.control.allow.methods = 
[32mkafka_1            |[0m 	controller.socket.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	consumer.iterator.backoff.ms = 50
[32mkafka_1            |[0m 	log.flush.interval.ms = null
[36mrest-proxy_1       |[0m 	access.control.allow.origin = 
[32mkafka_1            |[0m 	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
[36mrest-proxy_1       |[0m 	ssl.truststore.location = 
[32mkafka_1            |[0m 	replica.socket.receive.buffer.bytes = 65536
[36mrest-proxy_1       |[0m 	ssl.keystore.password = 
[32mkafka_1            |[0m 	min.insync.replicas = 1
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = 
[32mkafka_1            |[0m 	replica.fetch.wait.max.ms = 500
[36mrest-proxy_1       |[0m 	zookeeper.connect = localhost:2181
[32mkafka_1            |[0m 	num.recovery.threads.per.data.dir = 1
[36mrest-proxy_1       |[0m 	port = 8082
[32mkafka_1            |[0m 	ssl.keystore.type = JKS
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.size.max = 25
[32mkafka_1            |[0m 	default.replication.factor = 1
[36mrest-proxy_1       |[0m  (io.confluent.kafkarest.KafkaRestConfig:135)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,023] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread:64)
[32mkafka_1            |[0m 	ssl.truststore.password = null
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,027] INFO Client environment:zookeeper.version=3.4.3-1240972, built on 02/06/2012 10:48 GMT (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	log.preallocate = false
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,028] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper:98)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,028] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,028] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,028] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	replica.socket.timeout.ms = 30000
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,028] INFO Client environment:java.class.path=:/usr/bin/../target/kafka-rest-*-development/share/java/kafka-rest/*:/usr/bin/../share/java/confluent-common/slf4j-api-1.7.6.jar:/usr/bin/../share/java/confluent-common/common-utils-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-config-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-metrics-3.0.0.jar:/usr/bin/../share/java/confluent-common/jline-0.9.94.jar:/usr/bin/../share/java/confluent-common/zkclient-0.5.jar:/usr/bin/../share/java/confluent-common/netty-3.2.2.Final.jar:/usr/bin/../share/java/confluent-common/zookeeper-3.4.3.jar:/usr/bin/../share/java/confluent-common/log4j-1.2.17.jar:/usr/bin/../share/java/confluent-common/slf4j-log4j12-1.7.6.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-json-provider-2.5.4.jar:/usr/bin/../share/java/rest-utils/jetty-server-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jboss-logging-3.1.3.GA.jar:/usr/bin/../share/java/rest-utils/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/rest-utils/javassist-3.18.1-GA.jar:/usr/bin/../share/java/rest-utils/jersey-common-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-test-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-provider-jetty-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-security-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-util-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.el-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-http-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-base-2.5.4.jar:/usr/bin/../share/java/rest-utils/hk2-utils-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.el-api-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-io-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.inject-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.annotation-api-1.2.jar:/usr/bin/../share/java/rest-utils/junit-4.12.jar:/usr/bin/../share/java/rest-utils/rest-utils-examples-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-bean-validation-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-continuation-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/classmate-1.0.0.jar:/usr/bin/../share/java/rest-utils/hamcrest-core-1.3.jar:/usr/bin/../share/java/rest-utils/hibernate-validator-5.1.2.Final.jar:/usr/bin/../share/java/rest-utils/jetty-servlets-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jersey-client-2.19.jar:/usr/bin/../share/java/rest-utils/hk2-locator-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/aopalliance-repackaged-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-container-jetty-http-2.19.jar:/usr/bin/../share/java/rest-utils/jackson-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-core-2.19.jar:/usr/bin/../share/java/rest-utils/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/rest-utils/jackson-databind-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-server-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-servlet-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/hk2-api-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jackson-core-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-media-jaxb-2.19.jar:/usr/bin/../share/java/rest-utils/jersey-guava-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-3.0.0.jar:/usr/bin/../share/java/rest-utils/jackson-module-jaxb-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/asm-debug-all-5.0.3.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-core-2.19.jar:/usr/bin/../share/java/rest-utils/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-2.19.jar:/usr/bin/../share/java/kafka-rest/lz4-1.3.0.jar:/usr/bin/../share/java/kafka-rest/paranamer-2.3.jar:/usr/bin/../share/java/kafka-rest/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka-rest/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka-rest/netty-3.7.0.Final.jar:/usr/bin/../share/java/kafka-rest/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka-rest/kafka-json-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/zkclient-0.8.jar:/usr/bin/../share/java/kafka-rest/kafka-schema-registry-client-3.0.0.jar:/usr/bin/../share/java/kafka-rest/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka-rest/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka-rest/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka-rest/kafka-rest-3.0.0.jar:/usr/bin/../share/java/kafka-rest/xz-1.0.jar:/usr/bin/../share/java/kafka-rest/log4j-1.2.15.jar:/usr/bin/../share/java/kafka-rest/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/activation-1.1.jar:/usr/bin/../share/java/kafka-rest/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka-rest/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/avro-1.7.7.jar:/usr/bin/../share/java/kafka-rest/jline-0.9.94.jar:/usr/bin/../share/java/kafka-rest/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka-rest/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka-rest/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/kafka-avro-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/mail-1.4.jar (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	message.max.bytes = 1000012
[32mkafka_1            |[0m 	num.io.threads = 8
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,029] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	offsets.commit.required.acks = -1
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,029] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,029] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	delete.topic.enable = true
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,030] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	quota.window.size.seconds = 1
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,030] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	ssl.truststore.type = JKS
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,030] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	offsets.commit.timeout.ms = 5000
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,030] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper:98)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,030] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	quota.window.num = 11
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,031] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	zookeeper.connect = localhost:2181
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,032] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@75c072cb (org.apache.zookeeper.ZooKeeper:433)
[32mkafka_1            |[0m 	authorizer.class.name = 
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,040] INFO Opening socket connection to server /127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn:933)
[32mkafka_1            |[0m 	num.replica.fetchers = 1
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,041] INFO Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration. (org.apache.zookeeper.client.ZooKeeperSaslClient:125)
[32mkafka_1            |[0m 	log.retention.ms = null
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,090] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn:846)
[32mkafka_1            |[0m 	log.roll.jitter.hours = 0
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,096] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e80785b850002, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn:1175)
[32mkafka_1            |[0m 	log.cleaner.enable = true
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,097] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient:641)
[32mkafka_1            |[0m 	offsets.load.buffer.size = 5242880
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,328] INFO ProducerConfig values: 
[32mkafka_1            |[0m 	log.cleaner.delete.retention.ms = 86400000
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	ssl.client.auth = none
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m 	controlled.shutdown.max.retries = 3
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m 	queued.max.requests = 500
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m 	offsets.topic.replication.factor = 3
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m 	log.cleaner.threads = 1
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	sasl.kerberos.service.name = null
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	socket.request.max.bytes = 104857600
[32mkafka_1            |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m 	zookeeper.session.timeout.ms = 6000
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	log.retention.bytes = -1
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m 	log.message.timestamp.type = CreateTime
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m 	zookeeper.set.acl = false
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	connections.max.idle.ms = 600000
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m 	offsets.retention.minutes = 1440
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	replica.fetch.backoff.ms = 1000
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m 	inter.broker.protocol.version = 0.10.0-IV1
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m 	log.retention.hours = 168
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m 	num.partitions = 1
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m 	broker.id.generation.enable = true
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m 	listeners = null
[32mkafka_1            |[0m 	ssl.provider = null
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m 	log.roll.ms = null
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m 	ssl.cipher.suites = null
[36mrest-proxy_1       |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m 	log.index.size.max.bytes = 10485760
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m 	ssl.keymanager.algorithm = SunX509
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m 	replica.fetch.max.bytes = 1048576
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m 	advertised.port = null
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mkafka_1            |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m 	log.cleaner.io.buffer.size = 524288
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	zookeeper.connection.timeout.ms = 6000
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m 	log.roll.hours = 168
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m 	log.cleanup.policy = delete
[32mkafka_1            |[0m 	host.name = 
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m 	log.roll.jitter.ms = null
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m 	max.connections.per.ip = 2147483647
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m 	offsets.topic.segment.bytes = 104857600
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m 	background.threads = 10
[36mrest-proxy_1       |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m 	quota.consumer.default = 9223372036854775807
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m 	request.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m 	log.message.format.version = 0.10.0-IV1
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m 	log.index.interval.bytes = 4096
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m 	log.dir = /tmp/kafka-logs
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m 	log.segment.bytes = 1073741824
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,349] INFO ProducerConfig values: 
[32mkafka_1            |[0m 	log.cleaner.backoff.ms = 15000
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	offset.metadata.max.bytes = 4096
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m 	ssl.truststore.location = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m 	group.max.session.timeout.ms = 300000
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m 	zookeeper.sync.time.ms = 2000
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	port = 9092
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m 	log.retention.minutes = null
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	log.segment.delete.delay.ms = 60000
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m 	log.dirs = /var/lib/kafka
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	controlled.shutdown.enable = true
[36mrest-proxy_1       |[0m 	client.id = producer-1
[32mkafka_1            |[0m 	compression.type = producer
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	max.connections.per.ip.overrides = 
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m 	auto.leader.rebalance.enable = true
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m 	leader.imbalance.check.interval.seconds = 300
[32mkafka_1            |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m 	replica.lag.time.max.ms = 10000
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m 	num.network.threads = 3
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m 	ssl.key.password = null
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m 	reserved.broker.max.id = 1000
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m 	metrics.num.samples = 2
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m 	socket.send.buffer.bytes = 102400
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m 	ssl.protocol = TLS
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m 	socket.receive.buffer.bytes = 102400
[36mrest-proxy_1       |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m 	ssl.keystore.location = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m 	replica.fetch.min.bytes = 1
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m 	broker.rack = null
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m 	unclean.leader.election.enable = true
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[32mkafka_1            |[0m 	group.min.session.timeout.ms = 6000
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	offsets.retention.check.interval.ms = 600000
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m 	producer.purgatory.purge.interval.requests = 1000
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m 	metrics.sample.window.ms = 30000
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m 	broker.id = 0
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m 	offsets.topic.compression.codec = 0
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m 	log.retention.check.interval.ms = 300000
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m 	advertised.listeners = null
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m 	leader.imbalance.per.broker.percentage = 10
[36mrest-proxy_1       |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m  (kafka.server.KafkaConfig)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 21:43:22,297] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:22,298] INFO starting (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-18 21:43:22,302] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-18 21:43:22,311] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-18 21:43:22,315] INFO Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,351] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:43:22,315] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,351] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:43:22,315] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,351] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:43:22,315] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,351] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:43:22,315] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,353] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m [2019-11-18 21:43:22,315] INFO Client environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,353] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[32mkafka_1            |[0m [2019-11-18 21:43:22,316] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,354] INFO KafkaJsonSerializerConfig values: 
[36mrest-proxy_1       |[0m 	json.indent.output = false
[32mkafka_1            |[0m [2019-11-18 21:43:22,316] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 21:43:22,316] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,355] INFO KafkaJsonSerializerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:43:22,316] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka_1            |[0m [2019-11-18 21:43:22,316] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	json.indent.output = false
[32mkafka_1            |[0m [2019-11-18 21:43:22,316] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 21:43:22,316] INFO Client environment:user.name=confluent (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,355] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:43:22,316] INFO Client environment:user.home=/home/confluent (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 21:43:22,316] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-18 21:43:22,317] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@63355449 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-18 21:43:22,326] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-18 21:43:22,328] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 21:43:22,381] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:43:22,449] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e80785b850000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,451] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,635] INFO Loading logs. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m [2019-11-18 21:43:22,661] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-18 21:43:22,666] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,669] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:22,672] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-18 21:43:22,675] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 21:43:22,678] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:43:22,681] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-18 21:43:22,685] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,688] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,690] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m [2019-11-18 21:43:22,693] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-18 21:43:22,695] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:43:22,698] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 21:43:22,701] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-18 21:43:22,703] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-18 21:43:22,705] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:22,708] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m [2019-11-18 21:43:22,711] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,713] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 21:43:22,715] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 21:43:22,717] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 21:43:22,720] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-18 21:43:22,726] INFO Completed load of log mysimbdp-0 with log end offset 109 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,728] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 21:43:22,731] INFO Completed load of log _schemas-0 with log end offset 1 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 21:43:22,733] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-18 21:43:22,736] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 21:43:22,738] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 21:43:22,740] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 21:43:22,743] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,745] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-18 21:43:22,747] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-18 21:43:22,750] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,752] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-18 21:43:22,754] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-18 21:43:22,756] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m [2019-11-18 21:43:22,757] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-18 21:43:22,759] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 21:43:22,760] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:22,762] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-18 21:43:22,764] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-18 21:43:22,765] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,359] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:43:22,767] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 21:43:22,768] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-18 21:43:22,770] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-18 21:43:22,772] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-18 21:43:22,774] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-18 21:43:22,776] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:43:22,778] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 21:43:22,780] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,782] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,784] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	client.id = producer-2
[32mkafka_1            |[0m [2019-11-18 21:43:22,786] INFO Logs loading complete. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-18 21:43:22,850] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,851] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:22,879] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-18 21:43:22,881] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 21:43:22,892] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:43:22,892] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-18 21:43:22,918] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:22,927] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-18 21:43:22,928] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:43:23,458] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 21:43:23,459] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-18 21:43:23,460] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-18 21:43:23,481] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:23,481] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m [2019-11-18 21:43:23,482] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,491] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 21:43:23,492] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 21:43:23,501] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 21:43:23,517] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,534] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 21:43:23,536] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(rohit-X406UAR,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 21:43:23,543] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 21:43:23,543] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 21:43:23,543] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,684] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[mysimbdp,0],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[_schemas,0],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-18 21:43:23,915] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-18 21:43:23,922] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,922] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,930] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-18 21:43:23,930] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-18 21:43:23,931] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m [2019-11-18 21:43:23,931] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 21:43:23,934] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:23,934] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-18 21:43:23,936] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-18 21:43:23,936] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-18 21:43:23,938] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:23,938] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,359] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:43:23,941] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,359] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:43:23,941] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,359] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:43:23,943] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,359] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-18 21:43:23,943] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,359] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m [2019-11-18 21:43:23,945] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:23,946] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:23,948] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:23,948] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,359] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,464] INFO KafkaAvroSerializerConfig values: 
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m [2019-11-18 21:43:23,950] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m [2019-11-18 21:43:23,950] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 21:43:23,953] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,469] INFO KafkaAvroSerializerConfig values: 
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m [2019-11-18 21:43:23,953] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m [2019-11-18 21:43:23,955] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-18 21:43:23,955] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,469] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:43:23,958] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 21:43:23,958] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-18 21:43:23,960] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-18 21:43:23,960] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-18 21:43:23,962] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:23,963] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-18 21:43:23,965] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:43:23,965] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:43:23,967] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,967] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,969] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m [2019-11-18 21:43:23,969] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:23,972] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,972] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:23,975] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:23,975] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-18 21:43:23,977] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 21:43:23,978] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:43:23,979] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[mysimbdp,0],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[_schemas,0],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-18 21:43:23,980] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,980] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:23,983] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:23,983] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m [2019-11-18 21:43:23,986] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-18 21:43:23,986] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:23,989] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:43:23,989] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 21:43:23,992] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-18 21:43:23,992] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-18 21:43:23,994] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:23,994] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 21:43:23,997] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 21:43:23,997] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 21:43:23,999] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 21:43:23,999] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 21:43:24,002] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 21:43:24,002] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-18 21:43:24,004] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:24,004] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-18 21:43:24,007] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-18 21:43:24,007] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:24,009] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-18 21:43:24,009] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-18 21:43:24,011] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-18 21:43:24,012] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 21:43:24,014] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 21:43:24,014] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:24,016] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-18 21:43:24,016] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-18 21:43:24,019] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-18 21:43:24,019] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,473] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-18 21:43:24,026] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:24,027] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-18 21:43:24,027] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-18 21:43:24,027] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 21:43:24,028] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-18 21:43:24,028] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-18 21:43:24,029] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-18 21:43:24,029] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:43:24,030] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-18 21:43:24,030] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-18 21:43:24,031] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-18 21:43:24,031] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:24,031] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	client.id = producer-3
[32mkafka_1            |[0m [2019-11-18 21:43:24,031] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-18 21:43:24,032] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 21:43:24,046] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-18 21:43:24,047] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-18 21:43:24,047] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-18 21:43:24,048] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-18 21:43:24,048] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-18 21:43:24,049] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-18 21:43:24,049] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m [2019-11-18 21:43:24,050] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-18 21:53:23,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-18 22:03:23,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-18 22:10:31,553] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-18 22:10:31,556] INFO [KafkaApi-0] Auto creation of topic mysimbdp-clientReport with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-18 22:10:31,564] INFO [GroupCoordinator 0]: Preparing to restabilize group myGroup with old generation 0 (kafka.coordinator.GroupCoordinator)
[32mkafka_1            |[0m [2019-11-18 22:10:31,569] INFO [GroupCoordinator 0]: Stabilized group myGroup generation 1 (kafka.coordinator.GroupCoordinator)
[32mkafka_1            |[0m [2019-11-18 22:10:31,580] INFO [GroupCoordinator 0]: Assignment received from leader for group myGroup for generation 1 (kafka.coordinator.GroupCoordinator)
[32mkafka_1            |[0m [2019-11-18 22:10:31,887] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [mysimbdp-clientReport,0] (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 22:10:31,892] INFO Completed load of log mysimbdp-clientReport-0 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-18 22:10:31,896] INFO Created log for partition [mysimbdp-clientReport,0] in /var/lib/kafka with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-18 22:10:31,900] INFO Partition [mysimbdp-clientReport,0] on broker 0: No checkpointed highwatermark is found for partition [mysimbdp-clientReport,0] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-18 22:10:34,613] INFO [GroupCoordinator 0]: Preparing to restabilize group myGroup with old generation 1 (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-18 22:10:34,614] INFO [GroupCoordinator 0]: Stabilized group myGroup generation 2 (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-18 22:10:34,619] INFO [GroupCoordinator 0]: Assignment received from leader for group myGroup for generation 2 (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-18 22:13:23,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-18 22:23:23,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-18 22:27:06,020] INFO [GroupCoordinator 0]: Preparing to restabilize group myGroup with old generation 2 (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-18 22:27:06,022] INFO [GroupCoordinator 0]: Group myGroup generation 2 is dead and removed (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-18 22:33:23,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-18 22:43:12,406] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[32mkafka_1            |[0m [2019-11-18 22:43:12,410] INFO [KafkaApi-0] Auto creation of topic spark.out with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-18 22:43:12,745] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [spark.out,0] (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-18 22:43:12,749] INFO Completed load of log spark.out-0 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-18 22:43:12,751] INFO Created log for partition [spark.out,0] in /var/lib/kafka with properties {compression.type -> producer, message.format.version -> 0.10.0-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-18 22:43:12,752] INFO Partition [spark.out,0] on broker 0: No checkpointed highwatermark is found for partition [spark.out,0] (kafka.cluster.Partition)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-18 22:43:23,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-18 22:53:23,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-18 23:03:23,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-18 23:13:22,419] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-18 23:13:22,423] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-18 23:13:22,784] WARN Session 0x16e80785b850000 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m java.io.IOException: Connection reset by peer
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m 	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
[32mkafka_1            |[0m 	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,473] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,473] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,473] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,473] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[32mkafka_1            |[0m [2019-11-18 23:13:22,886] INFO zookeeper state changed (Disconnected) (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,473] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m [2019-11-18 23:13:22,886] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,473] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[32mkafka_1            |[0m [2019-11-18 23:13:23,479] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,482] INFO Verifying properties (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-18 23:13:24,516] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,483] INFO Property group.id is overridden to  (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-18 23:13:24,517] WARN Session 0x16e80785b850000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,484] WARN Property id is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m java.net.ConnectException: Connection refused
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,484] WARN Property port is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,484] WARN Property schema.registry.url is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,484] INFO Property zookeeper.connect is overridden to  (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,488] INFO KafkaAvroDeserializerConfig values: 
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m [2019-11-18 23:13:26,035] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m [2019-11-18 23:13:26,036] WARN Session 0x16e80785b850000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	specific.avro.reader = false
[32mkafka_1            |[0m java.net.ConnectException: Connection refused
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig:135)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,489] INFO KafkaJsonDecoderConfig values: 
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[36mrest-proxy_1       |[0m 	json.fail.unknown.properties = true
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonDecoderConfig:135)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,511] INFO Logging initialized @906ms (org.eclipse.jetty.util.log:186)
[32mkafka_1            |[0m [2019-11-18 23:13:27,718] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,520] WARN DEPRECATION warning: `listeners` configuration is not configured. Falling back to the deprecated `port` configuration. (io.confluent.rest.Application:248)
[32mkafka_1            |[0m [2019-11-18 23:13:27,719] WARN Session 0x16e80785b850000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,520] INFO Adding listener: http://0.0.0.0:8082 (io.confluent.rest.Application:137)
[32mkafka_1            |[0m java.net.ConnectException: Connection refused
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:33,562] INFO jetty-9.2.12.v20150709 (org.eclipse.jetty.server.Server:327)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:34,021] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version:27)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:34,166] INFO Started o.e.j.s.ServletContextHandler@26f96b85{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[32mkafka_1            |[0m [2019-11-18 23:13:29,543] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:34,170] INFO Started NetworkTrafficServerConnector@7e7f0f0a{HTTP/1.1}{0.0.0.0:8082} (org.eclipse.jetty.server.NetworkTrafficServerConnector:266)
[32mkafka_1            |[0m [2019-11-18 23:13:29,544] WARN Session 0x16e80785b850000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 21:43:34,171] INFO Started @1566ms (org.eclipse.jetty.server.Server:379)
[32mkafka_1            |[0m java.net.ConnectException: Connection refused
[36mrest-proxy_1       |[0m [2019-11-18 21:43:34,171] INFO Server started, listening for requests... (io.confluent.kafkarest.KafkaRestMain:38)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[36mrest-proxy_1       |[0m [2019-11-18 23:13:22,451] INFO Stopped NetworkTrafficServerConnector@7e7f0f0a{HTTP/1.1}{0.0.0.0:8082} (org.eclipse.jetty.server.NetworkTrafficServerConnector:306)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[36mrest-proxy_1       |[0m [2019-11-18 23:13:22,487] INFO Stopped o.e.j.s.ServletContextHandler@26f96b85{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:865)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[36mrest-proxy_1       |[0m [2019-11-18 23:13:22,491] INFO Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[32mkafka_1            |[0m [2019-11-18 23:13:31,363] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[32mkafka_1            |[0m [2019-11-18 23:13:31,363] WARN Session 0x16e80785b850000 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m [2019-11-18 23:13:22,494] INFO Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[32mkafka_1            |[0m java.net.ConnectException: Connection refused
[36mrest-proxy_1       |[0m [2019-11-18 23:13:22,496] INFO Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[36mrest-proxy_1       |[0m [2019-11-18 23:13:22,498] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread:82)
[32mkafka_1            |[0m 	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
[36mrest-proxy_1       |[0m [2019-11-18 23:13:22,900] INFO Session: 0x16e80785b850002 closed (org.apache.zookeeper.ZooKeeper:679)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
[36mrest-proxy_1       |[0m [2019-11-18 23:13:22,900] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn:511)
[32mkafka_1            |[0m 	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka-rest/kafka-rest.properties
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/server.properties
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable RP_ZOOKEEPER_CONNECT
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable KAFKA_ZOOKEEPER_CONNECT
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for schema.registry.url with value from environment variable RP_SCHEMA_REGISTRY_URL
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for log.dirs with value from environment variable KAFKA_LOG_DIRS
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka-rest/kafka-rest.properties
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/server.properties
[36mrest-proxy_1       |[0m SLF4J: Class path contains multiple SLF4J bindings.
[32mkafka_1            |[0m [2019-11-19 15:24:05,363] INFO KafkaConfig values: 
[32mkafka_1            |[0m 	advertised.host.name = null
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m 	metric.reporters = []
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/kafka-rest/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m 	quota.producer.default = 9223372036854775807
[32mkafka_1            |[0m 	offsets.topic.num.partitions = 50
[36mrest-proxy_1       |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[32mkafka_1            |[0m 	log.flush.interval.messages = 9223372036854775807
[36mrest-proxy_1       |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[32mkafka_1            |[0m 	auto.create.topics.enable = true
[32mkafka_1            |[0m 	controller.socket.timeout.ms = 30000
[32mkafka_1            |[0m 	log.flush.interval.ms = null
[36mrest-proxy_1       |[0m [2019-11-19 15:24:15,790] INFO KafkaRestConfig values: 
[32mkafka_1            |[0m 	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.timeout.ms = 1000
[32mkafka_1            |[0m 	replica.socket.receive.buffer.bytes = 65536
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	min.insync.replicas = 1
[36mrest-proxy_1       |[0m 	ssl.client.auth = false
[32mkafka_1            |[0m 	replica.fetch.wait.max.ms = 500
[32mkafka_1            |[0m 	num.recovery.threads.per.data.dir = 1
[36mrest-proxy_1       |[0m 	consumer.iterator.timeout.ms = 1
[32mkafka_1            |[0m 	ssl.keystore.type = JKS
[36mrest-proxy_1       |[0m 	response.mediatype.default = application/vnd.kafka.v1+json
[32mkafka_1            |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[32mkafka_1            |[0m 	default.replication.factor = 1
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	ssl.truststore.password = null
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = 
[32mkafka_1            |[0m 	log.preallocate = false
[36mrest-proxy_1       |[0m 	schema.registry.url = http://localhost:8081
[32mkafka_1            |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[36mrest-proxy_1       |[0m 	metrics.jmx.prefix = kafka.rest
[32mkafka_1            |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36mrest-proxy_1       |[0m 	request.logger.name = io.confluent.rest-utils.requests
[32mkafka_1            |[0m 	ssl.endpoint.identification.algorithm = null
[36mrest-proxy_1       |[0m 	ssl.key.password = 
[32mkafka_1            |[0m 	replica.socket.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	ssl.truststore.password = 
[32mkafka_1            |[0m 	message.max.bytes = 1000012
[36mrest-proxy_1       |[0m 	id = 1
[32mkafka_1            |[0m 	num.io.threads = 8
[36mrest-proxy_1       |[0m 	host.name = 
[32mkafka_1            |[0m 	offsets.commit.required.acks = -1
[36mrest-proxy_1       |[0m 	consumer.request.max.bytes = 67108864
[32mkafka_1            |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	delete.topic.enable = true
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = 
[32mkafka_1            |[0m 	quota.window.size.seconds = 1
[36mrest-proxy_1       |[0m 	consumer.threads = 1
[32mkafka_1            |[0m 	ssl.truststore.type = JKS
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	offsets.commit.timeout.ms = 5000
[36mrest-proxy_1       |[0m 	debug = false
[32mkafka_1            |[0m 	quota.window.num = 11
[36mrest-proxy_1       |[0m 	listeners = []
[32mkafka_1            |[0m 	zookeeper.connect = localhost:2181
[36mrest-proxy_1       |[0m 	ssl.provider = 
[32mkafka_1            |[0m 	authorizer.class.name = 
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = []
[32mkafka_1            |[0m 	num.replica.fetchers = 1
[36mrest-proxy_1       |[0m 	producer.threads = 5
[32mkafka_1            |[0m 	log.retention.ms = null
[36mrest-proxy_1       |[0m 	shutdown.graceful.ms = 1000
[32mkafka_1            |[0m 	log.roll.jitter.hours = 0
[32mkafka_1            |[0m 	log.cleaner.enable = true
[36mrest-proxy_1       |[0m 	ssl.keystore.location = 
[32mkafka_1            |[0m 	offsets.load.buffer.size = 5242880
[36mrest-proxy_1       |[0m 	response.mediatype.preferred = [application/vnd.kafka.v1+json, application/vnd.kafka+json, application/json]
[32mkafka_1            |[0m 	log.cleaner.delete.retention.ms = 86400000
[32mkafka_1            |[0m 	ssl.client.auth = none
[36mrest-proxy_1       |[0m 	consumer.request.timeout.ms = 1000
[32mkafka_1            |[0m 	controlled.shutdown.max.retries = 3
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = []
[32mkafka_1            |[0m 	queued.max.requests = 500
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	offsets.topic.replication.factor = 3
[36mrest-proxy_1       |[0m 	consumer.instance.timeout.ms = 300000
[32mkafka_1            |[0m 	log.cleaner.threads = 1
[36mrest-proxy_1       |[0m 	access.control.allow.methods = 
[32mkafka_1            |[0m 	sasl.kerberos.service.name = null
[36mrest-proxy_1       |[0m 	consumer.iterator.backoff.ms = 50
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mrest-proxy_1       |[0m 	access.control.allow.origin = 
[32mkafka_1            |[0m 	socket.request.max.bytes = 104857600
[36mrest-proxy_1       |[0m 	ssl.truststore.location = 
[32mkafka_1            |[0m 	ssl.trustmanager.algorithm = PKIX
[36mrest-proxy_1       |[0m 	ssl.keystore.password = 
[32mkafka_1            |[0m 	zookeeper.session.timeout.ms = 6000
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = 
[32mkafka_1            |[0m 	log.retention.bytes = -1
[32mkafka_1            |[0m 	log.message.timestamp.type = CreateTime
[36mrest-proxy_1       |[0m 	zookeeper.connect = localhost:2181
[32mkafka_1            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mrest-proxy_1       |[0m 	port = 8082
[32mkafka_1            |[0m 	zookeeper.set.acl = false
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m 	connections.max.idle.ms = 600000
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.size.max = 25
[32mkafka_1            |[0m 	offsets.retention.minutes = 1440
[36mrest-proxy_1       |[0m  (io.confluent.kafkarest.KafkaRestConfig:135)
[32mkafka_1            |[0m 	replica.fetch.backoff.ms = 1000
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,015] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread:64)
[32mkafka_1            |[0m 	inter.broker.protocol.version = 0.10.0-IV1
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,019] INFO Client environment:zookeeper.version=3.4.3-1240972, built on 02/06/2012 10:48 GMT (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	log.retention.hours = 168
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,020] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	num.partitions = 1
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,020] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	broker.id.generation.enable = true
[32mkafka_1            |[0m 	listeners = null
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,020] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	ssl.provider = null
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,021] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m 	log.roll.ms = null
[32mkafka_1            |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,021] INFO Client environment:java.class.path=:/usr/bin/../target/kafka-rest-*-development/share/java/kafka-rest/*:/usr/bin/../share/java/confluent-common/slf4j-api-1.7.6.jar:/usr/bin/../share/java/confluent-common/common-utils-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-config-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-metrics-3.0.0.jar:/usr/bin/../share/java/confluent-common/jline-0.9.94.jar:/usr/bin/../share/java/confluent-common/zkclient-0.5.jar:/usr/bin/../share/java/confluent-common/netty-3.2.2.Final.jar:/usr/bin/../share/java/confluent-common/zookeeper-3.4.3.jar:/usr/bin/../share/java/confluent-common/log4j-1.2.17.jar:/usr/bin/../share/java/confluent-common/slf4j-log4j12-1.7.6.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-json-provider-2.5.4.jar:/usr/bin/../share/java/rest-utils/jetty-server-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jboss-logging-3.1.3.GA.jar:/usr/bin/../share/java/rest-utils/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/rest-utils/javassist-3.18.1-GA.jar:/usr/bin/../share/java/rest-utils/jersey-common-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-test-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-provider-jetty-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-security-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-util-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.el-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-http-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-base-2.5.4.jar:/usr/bin/../share/java/rest-utils/hk2-utils-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.el-api-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-io-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.inject-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.annotation-api-1.2.jar:/usr/bin/../share/java/rest-utils/junit-4.12.jar:/usr/bin/../share/java/rest-utils/rest-utils-examples-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-bean-validation-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-continuation-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/classmate-1.0.0.jar:/usr/bin/../share/java/rest-utils/hamcrest-core-1.3.jar:/usr/bin/../share/java/rest-utils/hibernate-validator-5.1.2.Final.jar:/usr/bin/../share/java/rest-utils/jetty-servlets-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jersey-client-2.19.jar:/usr/bin/../share/java/rest-utils/hk2-locator-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/aopalliance-repackaged-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-container-jetty-http-2.19.jar:/usr/bin/../share/java/rest-utils/jackson-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-core-2.19.jar:/usr/bin/../share/java/rest-utils/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/rest-utils/jackson-databind-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-server-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-servlet-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/hk2-api-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jackson-core-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-media-jaxb-2.19.jar:/usr/bin/../share/java/rest-utils/jersey-guava-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-3.0.0.jar:/usr/bin/../share/java/rest-utils/jackson-module-jaxb-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/asm-debug-all-5.0.3.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-core-2.19.jar:/usr/bin/../share/java/rest-utils/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-2.19.jar:/usr/bin/../share/java/kafka-rest/lz4-1.3.0.jar:/usr/bin/../share/java/kafka-rest/paranamer-2.3.jar:/usr/bin/../share/java/kafka-rest/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka-rest/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka-rest/netty-3.7.0.Final.jar:/usr/bin/../share/java/kafka-rest/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka-rest/kafka-json-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/zkclient-0.8.jar:/usr/bin/../share/java/kafka-rest/kafka-schema-registry-client-3.0.0.jar:/usr/bin/../share/java/kafka-rest/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka-rest/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka-rest/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka-rest/kafka-rest-3.0.0.jar:/usr/bin/../share/java/kafka-rest/xz-1.0.jar:/usr/bin/../share/java/kafka-rest/log4j-1.2.15.jar:/usr/bin/../share/java/kafka-rest/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/activation-1.1.jar:/usr/bin/../share/java/kafka-rest/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka-rest/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/avro-1.7.7.jar:/usr/bin/../share/java/kafka-rest/jline-0.9.94.jar:/usr/bin/../share/java/kafka-rest/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka-rest/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka-rest/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/kafka-avro-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/mail-1.4.jar (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m 	log.index.size.max.bytes = 10485760
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,021] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	ssl.keymanager.algorithm = SunX509
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,022] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,022] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	replica.fetch.max.bytes = 1048576
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,022] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	advertised.port = null
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,022] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,022] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,022] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	log.cleaner.io.buffer.size = 524288
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,022] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,023] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m 	zookeeper.connection.timeout.ms = 6000
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,024] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@75c072cb (org.apache.zookeeper.ZooKeeper:433)
[32mkafka_1            |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,033] INFO Opening socket connection to server /127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn:933)
[32mkafka_1            |[0m 	log.roll.hours = 168
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,034] INFO Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration. (org.apache.zookeeper.client.ZooKeeperSaslClient:125)
[32mkafka_1            |[0m 	log.cleanup.policy = delete
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,078] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn:846)
[32mkafka_1            |[0m 	host.name = 
[32mkafka_1            |[0m 	log.roll.jitter.ms = null
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,084] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e84437a690002, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn:1175)
[32mkafka_1            |[0m 	max.connections.per.ip = 2147483647
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,085] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient:641)
[32mkafka_1            |[0m 	offsets.topic.segment.bytes = 104857600
[32mkafka_1            |[0m 	background.threads = 10
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,248] INFO ProducerConfig values: 
[32mkafka_1            |[0m 	quota.consumer.default = 9223372036854775807
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	request.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m 	log.message.format.version = 0.10.0-IV1
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m 	log.index.interval.bytes = 4096
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m 	log.dir = /tmp/kafka-logs
[36mrest-proxy_1       |[0m 	bootstrap.servers = []
[32mkafka_1            |[0m 	log.segment.bytes = 1073741824
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	log.cleaner.backoff.ms = 15000
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m 	offset.metadata.max.bytes = 4096
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	ssl.truststore.location = null
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m 	group.max.session.timeout.ms = 300000
[32mkafka_1            |[0m 	ssl.keystore.password = null
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	zookeeper.sync.time.ms = 2000
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m 	port = 9092
[32mkafka_1            |[0m 	log.retention.minutes = null
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	log.segment.delete.delay.ms = 60000
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m 	log.dirs = /var/lib/kafka
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	controlled.shutdown.enable = true
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m 	compression.type = producer
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	max.connections.per.ip.overrides = 
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mkafka_1            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m 	auto.leader.rebalance.enable = true
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m 	leader.imbalance.check.interval.seconds = 300
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m 	replica.lag.time.max.ms = 10000
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m 	num.network.threads = 3
[36mrest-proxy_1       |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m 	ssl.key.password = null
[32mkafka_1            |[0m 	reserved.broker.max.id = 1000
[32mkafka_1            |[0m 	metrics.num.samples = 2
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m 	socket.send.buffer.bytes = 102400
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	socket.receive.buffer.bytes = 102400
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m 	ssl.keystore.location = null
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m 	replica.fetch.min.bytes = 1
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m 	broker.rack = null
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m 	unclean.leader.election.enable = true
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	group.min.session.timeout.ms = 6000
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m 	offsets.retention.check.interval.ms = 600000
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m 	producer.purgatory.purge.interval.requests = 1000
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m 	metrics.sample.window.ms = 30000
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m 	broker.id = 0
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m 	offsets.topic.compression.codec = 0
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m 	log.retention.check.interval.ms = 300000
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m 	advertised.listeners = null
[36mrest-proxy_1       |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m 	leader.imbalance.per.broker.percentage = 10
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m  (kafka.server.KafkaConfig)
[32mkafka_1            |[0m [2019-11-19 15:24:05,429] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:05,430] INFO starting (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-19 15:24:05,438] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[32mkafka_1            |[0m [2019-11-19 15:24:05,451] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-19 15:24:05,459] INFO Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-19 15:24:05,459] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,267] INFO Closing the Kafka producer with timeoutMillis = 0 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[32mkafka_1            |[0m [2019-11-19 15:24:05,459] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m [2019-11-19 15:24:16,269] ERROR Server died unexpectedly: org.apache.kafka.common.KafkaException: Failed to construct kafka producer (io.confluent.kafkarest.KafkaRestMain:44)
[32mkafka_1            |[0m [2019-11-19 15:24:05,459] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka-rest/kafka-rest.properties
[32mkafka_1            |[0m [2019-11-19 15:24:05,459] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable RP_ZOOKEEPER_CONNECT
[32mkafka_1            |[0m [2019-11-19 15:24:05,459] INFO Client environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for schema.registry.url with value from environment variable RP_SCHEMA_REGISTRY_URL
[32mkafka_1            |[0m [2019-11-19 15:24:05,459] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka-rest/kafka-rest.properties
[32mkafka_1            |[0m [2019-11-19 15:24:05,460] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m SLF4J: Class path contains multiple SLF4J bindings.
[32mkafka_1            |[0m [2019-11-19 15:24:05,460] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m [2019-11-19 15:24:05,460] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mkafka_1            |[0m [2019-11-19 15:24:05,460] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m SLF4J: Found binding in [jar:file:/usr/share/java/kafka-rest/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[32mkafka_1            |[0m [2019-11-19 15:24:05,460] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[32mkafka_1            |[0m [2019-11-19 15:24:05,460] INFO Client environment:user.name=confluent (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,387] INFO KafkaRestConfig values: 
[32mkafka_1            |[0m [2019-11-19 15:24:05,460] INFO Client environment:user.home=/home/confluent (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.timeout.ms = 1000
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-19 15:24:05,460] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.client.auth = false
[36mrest-proxy_1       |[0m 	consumer.iterator.timeout.ms = 1
[32mkafka_1            |[0m [2019-11-19 15:24:05,461] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@63355449 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	response.mediatype.default = application/vnd.kafka.v1+json
[32mkafka_1            |[0m [2019-11-19 15:24:05,477] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-19 15:24:05,482] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,543] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[32mkafka_1            |[0m [2019-11-19 15:24:05,615] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e84437a690000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	schema.registry.url = http://localhost:8081
[32mkafka_1            |[0m [2019-11-19 15:24:05,617] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m 	metrics.jmx.prefix = kafka.rest
[32mkafka_1            |[0m [2019-11-19 15:24:05,795] INFO Loading logs. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-19 15:24:05,828] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-49/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	request.logger.name = io.confluent.rest-utils.requests
[32mkafka_1            |[0m [2019-11-19 15:24:05,835] INFO Recovering unflushed segment 0 in log __consumer_offsets-49. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.key.password = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,837] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,842] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-7/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	id = 1
[32mkafka_1            |[0m [2019-11-19 15:24:05,842] INFO Recovering unflushed segment 0 in log __consumer_offsets-7. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	host.name = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,843] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	consumer.request.max.bytes = 67108864
[32mkafka_1            |[0m [2019-11-19 15:24:05,847] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-44/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-19 15:24:05,847] INFO Recovering unflushed segment 0 in log __consumer_offsets-44. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,849] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	consumer.threads = 1
[32mkafka_1            |[0m [2019-11-19 15:24:05,852] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-3/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-19 15:24:05,852] INFO Recovering unflushed segment 0 in log __consumer_offsets-3. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	debug = false
[32mkafka_1            |[0m [2019-11-19 15:24:05,853] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	listeners = []
[32mkafka_1            |[0m [2019-11-19 15:24:05,856] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-24/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.provider = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,856] INFO Recovering unflushed segment 0 in log __consumer_offsets-24. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = []
[32mkafka_1            |[0m [2019-11-19 15:24:05,857] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	producer.threads = 5
[32mkafka_1            |[0m [2019-11-19 15:24:05,860] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-30/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	shutdown.graceful.ms = 1000
[36mrest-proxy_1       |[0m 	ssl.keystore.location = 
[36mrest-proxy_1       |[0m 	response.mediatype.preferred = [application/vnd.kafka.v1+json, application/vnd.kafka+json, application/json]
[32mkafka_1            |[0m [2019-11-19 15:24:05,860] INFO Recovering unflushed segment 0 in log __consumer_offsets-30. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	consumer.request.timeout.ms = 1000
[32mkafka_1            |[0m [2019-11-19 15:24:05,861] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = []
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-19 15:24:05,865] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-21/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,865] INFO Recovering unflushed segment 0 in log __consumer_offsets-21. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	consumer.instance.timeout.ms = 300000
[32mkafka_1            |[0m [2019-11-19 15:24:05,866] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	access.control.allow.methods = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,869] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-37/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,869] INFO Recovering unflushed segment 0 in log __consumer_offsets-37. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	consumer.iterator.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-19 15:24:05,870] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	access.control.allow.origin = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,872] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-0/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,872] INFO Recovering unflushed segment 0 in log __consumer_offsets-0. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,873] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,876] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-26/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	zookeeper.connect = localhost:2181
[32mkafka_1            |[0m [2019-11-19 15:24:05,876] INFO Recovering unflushed segment 0 in log __consumer_offsets-26. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	port = 8082
[32mkafka_1            |[0m [2019-11-19 15:24:05,877] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:05,880] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-38/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	simpleconsumer.pool.size.max = 25
[32mkafka_1            |[0m [2019-11-19 15:24:05,881] INFO Recovering unflushed segment 0 in log __consumer_offsets-38. (kafka.log.Log)
[36mrest-proxy_1       |[0m  (io.confluent.kafkarest.KafkaRestConfig:135)
[32mkafka_1            |[0m [2019-11-19 15:24:05,881] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,883] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-12/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,884] INFO Recovering unflushed segment 0 in log __consumer_offsets-12. (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,884] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,600] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread:64)
[32mkafka_1            |[0m [2019-11-19 15:24:05,887] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-25/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,605] INFO Client environment:zookeeper.version=3.4.3-1240972, built on 02/06/2012 10:48 GMT (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,887] INFO Recovering unflushed segment 0 in log __consumer_offsets-25. (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,605] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,888] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,606] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,890] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-28/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,606] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,891] INFO Recovering unflushed segment 0 in log __consumer_offsets-28. (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,606] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,891] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,606] INFO Client environment:java.class.path=:/usr/bin/../target/kafka-rest-*-development/share/java/kafka-rest/*:/usr/bin/../share/java/confluent-common/slf4j-api-1.7.6.jar:/usr/bin/../share/java/confluent-common/common-utils-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-config-3.0.0.jar:/usr/bin/../share/java/confluent-common/common-metrics-3.0.0.jar:/usr/bin/../share/java/confluent-common/jline-0.9.94.jar:/usr/bin/../share/java/confluent-common/zkclient-0.5.jar:/usr/bin/../share/java/confluent-common/netty-3.2.2.Final.jar:/usr/bin/../share/java/confluent-common/zookeeper-3.4.3.jar:/usr/bin/../share/java/confluent-common/log4j-1.2.17.jar:/usr/bin/../share/java/confluent-common/slf4j-log4j12-1.7.6.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-json-provider-2.5.4.jar:/usr/bin/../share/java/rest-utils/jetty-server-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jboss-logging-3.1.3.GA.jar:/usr/bin/../share/java/rest-utils/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/rest-utils/javassist-3.18.1-GA.jar:/usr/bin/../share/java/rest-utils/jersey-common-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-test-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-provider-jetty-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-security-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jetty-util-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.el-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-http-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jackson-jaxrs-base-2.5.4.jar:/usr/bin/../share/java/rest-utils/hk2-utils-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.el-api-2.2.4.jar:/usr/bin/../share/java/rest-utils/jetty-io-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/javax.inject-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/javax.annotation-api-1.2.jar:/usr/bin/../share/java/rest-utils/junit-4.12.jar:/usr/bin/../share/java/rest-utils/rest-utils-examples-3.0.0.jar:/usr/bin/../share/java/rest-utils/jersey-bean-validation-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-continuation-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/classmate-1.0.0.jar:/usr/bin/../share/java/rest-utils/hamcrest-core-1.3.jar:/usr/bin/../share/java/rest-utils/hibernate-validator-5.1.2.Final.jar:/usr/bin/../share/java/rest-utils/jetty-servlets-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/jersey-client-2.19.jar:/usr/bin/../share/java/rest-utils/hk2-locator-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/aopalliance-repackaged-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jersey-container-jetty-http-2.19.jar:/usr/bin/../share/java/rest-utils/jackson-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-core-2.19.jar:/usr/bin/../share/java/rest-utils/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/rest-utils/jackson-databind-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-server-2.19.jar:/usr/bin/../share/java/rest-utils/jetty-servlet-9.2.12.v20150709.jar:/usr/bin/../share/java/rest-utils/hk2-api-2.4.0-b25.jar:/usr/bin/../share/java/rest-utils/jackson-core-2.5.4.jar:/usr/bin/../share/java/rest-utils/jersey-media-jaxb-2.19.jar:/usr/bin/../share/java/rest-utils/jersey-guava-2.19.jar:/usr/bin/../share/java/rest-utils/rest-utils-3.0.0.jar:/usr/bin/../share/java/rest-utils/jackson-module-jaxb-annotations-2.5.4.jar:/usr/bin/../share/java/rest-utils/asm-debug-all-5.0.3.jar:/usr/bin/../share/java/rest-utils/jersey-test-framework-core-2.19.jar:/usr/bin/../share/java/rest-utils/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/rest-utils/jersey-container-servlet-2.19.jar:/usr/bin/../share/java/kafka-rest/lz4-1.3.0.jar:/usr/bin/../share/java/kafka-rest/paranamer-2.3.jar:/usr/bin/../share/java/kafka-rest/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka-rest/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka-rest/netty-3.7.0.Final.jar:/usr/bin/../share/java/kafka-rest/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka-rest/kafka-json-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/zkclient-0.8.jar:/usr/bin/../share/java/kafka-rest/kafka-schema-registry-client-3.0.0.jar:/usr/bin/../share/java/kafka-rest/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka-rest/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka-rest/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka-rest/kafka-rest-3.0.0.jar:/usr/bin/../share/java/kafka-rest/xz-1.0.jar:/usr/bin/../share/java/kafka-rest/log4j-1.2.15.jar:/usr/bin/../share/java/kafka-rest/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka-rest/activation-1.1.jar:/usr/bin/../share/java/kafka-rest/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka-rest/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/avro-1.7.7.jar:/usr/bin/../share/java/kafka-rest/jline-0.9.94.jar:/usr/bin/../share/java/kafka-rest/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka-rest/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka-rest/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka-rest/kafka-avro-serializer-3.0.0.jar:/usr/bin/../share/java/kafka-rest/mail-1.4.jar (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,894] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-45/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,606] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,894] INFO Recovering unflushed segment 0 in log __consumer_offsets-45. (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,607] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,895] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,607] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,897] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-36/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,607] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,898] INFO Recovering unflushed segment 0 in log __consumer_offsets-36. (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,607] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper:98)
[32mkafka_1            |[0m [2019-11-19 15:24:05,898] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,607] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper:98)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,607] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper:98)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,607] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper:98)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,608] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper:98)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,609] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@75c072cb (org.apache.zookeeper.ZooKeeper:433)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,618] INFO Opening socket connection to server /127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn:933)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,620] INFO Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration. (org.apache.zookeeper.client.ZooKeeperSaslClient:125)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,666] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn:846)
[32mkafka_1            |[0m [2019-11-19 15:24:05,900] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-15/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,672] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e8445b9100002, negotiated timeout = 30000 (org.apache.zookeeper.ClientCnxn:1175)
[32mkafka_1            |[0m [2019-11-19 15:24:05,901] INFO Recovering unflushed segment 0 in log __consumer_offsets-15. (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,901] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,903] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-6/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,673] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient:641)
[32mkafka_1            |[0m [2019-11-19 15:24:05,904] INFO Recovering unflushed segment 0 in log __consumer_offsets-6. (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,930] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-19 15:24:05,904] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-19 15:24:05,906] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-35/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-19 15:24:05,907] INFO Recovering unflushed segment 0 in log __consumer_offsets-35. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-19 15:24:05,907] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-19 15:24:05,910] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-1/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-19 15:24:05,910] INFO Recovering unflushed segment 0 in log __consumer_offsets-1. (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,911] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-19 15:24:05,914] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-13/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-19 15:24:05,914] INFO Recovering unflushed segment 0 in log __consumer_offsets-13. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-19 15:24:05,914] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,916] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-23/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,917] INFO Recovering unflushed segment 0 in log __consumer_offsets-23. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m [2019-11-19 15:24:05,917] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:05,919] WARN Found a corrupted index file, /var/lib/kafka/mysimbdp-0/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-19 15:24:05,941] INFO Recovering unflushed segment 0 in log mysimbdp-0. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-19 15:24:05,949] INFO Completed load of log mysimbdp-0 with log end offset 524 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,951] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-27/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-19 15:24:05,952] INFO Recovering unflushed segment 0 in log __consumer_offsets-27. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-19 15:24:05,952] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,954] WARN Found a corrupted index file, /var/lib/kafka/_schemas-0/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,955] INFO Recovering unflushed segment 0 in log _schemas-0. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m [2019-11-19 15:24:05,955] INFO Completed load of log _schemas-0 with log end offset 1 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-19 15:24:05,957] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-34/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-19 15:24:05,958] INFO Recovering unflushed segment 0 in log __consumer_offsets-34. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-19 15:24:05,958] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-19 15:24:05,960] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-9/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-19 15:24:05,961] INFO Recovering unflushed segment 0 in log __consumer_offsets-9. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:05,962] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m [2019-11-19 15:24:05,964] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-46/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-19 15:24:05,965] INFO Recovering unflushed segment 0 in log __consumer_offsets-46. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-19 15:24:05,965] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-19 15:24:05,968] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-22/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,968] INFO Recovering unflushed segment 0 in log __consumer_offsets-22. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-19 15:24:05,969] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-19 15:24:05,972] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-19/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-19 15:24:05,972] INFO Recovering unflushed segment 0 in log __consumer_offsets-19. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-19 15:24:05,973] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-19 15:24:05,975] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-8/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,976] INFO Recovering unflushed segment 0 in log __consumer_offsets-8. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-19 15:24:05,976] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-19 15:24:05,979] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-20/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,979] INFO Recovering unflushed segment 0 in log __consumer_offsets-20. (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:05,980] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,982] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-42/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-19 15:24:05,983] INFO Recovering unflushed segment 0 in log __consumer_offsets-42. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[36mrest-proxy_1       |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m [2019-11-19 15:24:05,983] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-19 15:24:05,985] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-16/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:05,985] INFO Recovering unflushed segment 0 in log __consumer_offsets-16. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-19 15:24:05,985] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-19 15:24:05,987] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-39/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-19 15:24:05,988] INFO Recovering unflushed segment 0 in log __consumer_offsets-39. (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,958] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-19 15:24:05,988] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-19 15:24:05,990] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-31/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-19 15:24:05,990] INFO Recovering unflushed segment 0 in log __consumer_offsets-31. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-19 15:24:05,990] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-19 15:24:05,992] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-33/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m [2019-11-19 15:24:05,992] INFO Recovering unflushed segment 0 in log __consumer_offsets-33. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,993] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,994] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-48/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	client.id = producer-1
[32mkafka_1            |[0m [2019-11-19 15:24:05,995] INFO Recovering unflushed segment 0 in log __consumer_offsets-48. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m [2019-11-19 15:24:05,995] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:05,997] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-47/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m [2019-11-19 15:24:05,997] INFO Recovering unflushed segment 0 in log __consumer_offsets-47. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m [2019-11-19 15:24:05,998] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-19 15:24:06,000] WARN Found a corrupted index file, /var/lib/kafka/mysimbdp-clientReport-0/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-19 15:24:06,001] INFO Recovering unflushed segment 0 in log mysimbdp-clientReport-0. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-19 15:24:06,003] INFO Completed load of log mysimbdp-clientReport-0 with log end offset 131 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-19 15:24:06,006] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-4/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:06,006] INFO Recovering unflushed segment 0 in log __consumer_offsets-4. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m [2019-11-19 15:24:06,007] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-19 15:24:06,009] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-43/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:06,009] INFO Recovering unflushed segment 0 in log __consumer_offsets-43. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-19 15:24:06,009] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-19 15:24:06,012] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-40/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-19 15:24:06,013] INFO Recovering unflushed segment 0 in log __consumer_offsets-40. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-19 15:24:06,013] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:06,015] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-17/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m [2019-11-19 15:24:06,017] INFO Recovering unflushed segment 0 in log __consumer_offsets-17. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-19 15:24:06,019] INFO Completed load of log __consumer_offsets-17 with log end offset 194 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:06,021] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-10/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-19 15:24:06,021] INFO Recovering unflushed segment 0 in log __consumer_offsets-10. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-19 15:24:06,021] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-19 15:24:06,023] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-18/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-19 15:24:06,023] INFO Recovering unflushed segment 0 in log __consumer_offsets-18. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-19 15:24:06,024] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-19 15:24:06,025] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-29/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-19 15:24:06,026] INFO Recovering unflushed segment 0 in log __consumer_offsets-29. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-19 15:24:06,026] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-19 15:24:06,028] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-11/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-19 15:24:06,028] INFO Recovering unflushed segment 0 in log __consumer_offsets-11. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-19 15:24:06,028] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-19 15:24:06,030] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-5/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-19 15:24:06,031] INFO Recovering unflushed segment 0 in log __consumer_offsets-5. (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:06,031] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-19 15:24:06,033] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-41/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-19 15:24:06,033] INFO Recovering unflushed segment 0 in log __consumer_offsets-41. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-19 15:24:06,034] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mkafka_1            |[0m [2019-11-19 15:24:06,036] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-2/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-19 15:24:06,036] INFO Recovering unflushed segment 0 in log __consumer_offsets-2. (kafka.log.Log)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:06,037] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-19 15:24:06,039] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-32/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-19 15:24:06,039] INFO Recovering unflushed segment 0 in log __consumer_offsets-32. (kafka.log.Log)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-19 15:24:06,039] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:24:06,042] WARN Found a corrupted index file, /var/lib/kafka/spark.out-0/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,960] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-19 15:24:06,043] INFO Recovering unflushed segment 0 in log spark.out-0. (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,960] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-19 15:24:06,043] INFO Completed load of log spark.out-0 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,960] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-19 15:24:06,046] WARN Found a corrupted index file, /var/lib/kafka/__consumer_offsets-14/00000000000000000000.index, deleting and rebuilding index... (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,960] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-19 15:24:06,046] INFO Recovering unflushed segment 0 in log __consumer_offsets-14. (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,963] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m [2019-11-19 15:24:06,047] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,963] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,969] INFO KafkaJsonSerializerConfig values: 
[32mkafka_1            |[0m [2019-11-19 15:24:06,049] INFO Logs loading complete. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	json.indent.output = false
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-19 15:24:06,126] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-19 15:24:06,128] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-19 15:24:06,163] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,969] INFO KafkaJsonSerializerConfig values: 
[32mkafka_1            |[0m [2019-11-19 15:24:06,165] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[36mrest-proxy_1       |[0m 	json.indent.output = false
[32mkafka_1            |[0m [2019-11-19 15:24:06,181] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonSerializerConfig:135)
[32mkafka_1            |[0m [2019-11-19 15:24:06,182] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,970] INFO ProducerConfig values: 
[32mkafka_1            |[0m [2019-11-19 15:24:06,223] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 15:24:06,224] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m [2019-11-19 15:24:06,277] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m [2019-11-19 15:24:06,278] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[32mkafka_1            |[0m [2019-11-19 15:24:06,282] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m [2019-11-19 15:24:06,302] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m [2019-11-19 15:24:06,303] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 15:24:06,330] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-19 15:24:06,368] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m [2019-11-19 15:24:06,387] INFO Result of znode creation is: NODEEXISTS (kafka.utils.ZKCheckedEphemeral)
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m [2019-11-19 15:24:06,391] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m java.lang.RuntimeException: A broker is already registered on the path /brokers/ids/0. This probably indicates that you either have configured a brokerid that is already in use, or else you have shutdown this broker and restarted it faster than the zookeeper timeout so it appears to be re-registering.
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m 	at kafka.utils.ZkUtils.registerBrokerInZk(ZkUtils.scala:305)
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	at kafka.utils.ZkUtils.registerBrokerInZk(ZkUtils.scala:291)
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m 	at kafka.server.KafkaHealthcheck.register(KafkaHealthcheck.scala:70)
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	at kafka.server.KafkaHealthcheck.startup(KafkaHealthcheck.scala:51)
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m 	at kafka.server.KafkaServer.startup(KafkaServer.scala:244)
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	at io.confluent.support.metrics.SupportedServerStartable.startup(SupportedServerStartable.java:100)
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m 	at io.confluent.support.metrics.SupportedKafka.main(SupportedKafka.java:49)
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m [2019-11-19 15:24:06,394] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m [2019-11-19 15:24:06,396] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m [2019-11-19 15:24:06,447] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-19 15:24:06,448] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m [2019-11-19 15:24:06,475] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-19 15:24:06,477] INFO [ThrottledRequestReaper-Produce], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 15:24:07,304] INFO [ThrottledRequestReaper-Produce], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-19 15:24:07,304] INFO [ThrottledRequestReaper-Produce], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-19 15:24:07,304] INFO [ThrottledRequestReaper-Fetch], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 15:24:08,304] INFO [ThrottledRequestReaper-Fetch], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-19 15:24:08,304] INFO [ThrottledRequestReaper-Fetch], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-19 15:24:08,306] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:08,308] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m [2019-11-19 15:24:08,309] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-19 15:24:08,311] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m [2019-11-19 15:24:08,311] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-19 15:24:08,384] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m [2019-11-19 15:24:08,384] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-19 15:24:08,385] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 15:24:08,584] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-19 15:24:08,584] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-19 15:24:08,589] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[32mkafka_1            |[0m [2019-11-19 15:24:08,591] INFO Shutting down. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-19 15:24:08,729] INFO Shutdown complete. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-19 15:24:08,730] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-19 15:24:08,731] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 15:24:08,840] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 15:24:08,841] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-19 15:24:08,841] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-19 15:24:09,040] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-19 15:24:09,040] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-19 15:24:09,042] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.GroupCoordinator)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-19 15:24:09,051] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m [2019-11-19 15:24:09,056] INFO Session: 0x16e84437a690000 closed (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-19 15:24:09,056] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:24:09,063] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-19 15:24:09,065] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:125) - Reading properties from /etc/kafka/server.properties
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,975] INFO ProducerConfig values: 
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for zookeeper.connect with value from environment variable KAFKA_ZOOKEEPER_CONNECT
[36mrest-proxy_1       |[0m 	metric.reporters = []
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:112) - Overriding value for log.dirs with value from environment variable KAFKA_LOG_DIRS
[32mkafka_1            |[0m  INFO [main] (PropertyEditor.java:147) - Writing properties to /etc/kafka/server.properties
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m [2019-11-19 15:26:32,823] INFO KafkaConfig values: 
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	advertised.host.name = null
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	quota.producer.default = 9223372036854775807
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	offsets.topic.num.partitions = 50
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m 	log.flush.interval.messages = 9223372036854775807
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	auto.create.topics.enable = true
[36mrest-proxy_1       |[0m 	client.id = producer-2
[32mkafka_1            |[0m 	controller.socket.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	log.flush.interval.ms = null
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m 	replica.socket.receive.buffer.bytes = 65536
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	min.insync.replicas = 1
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m 	replica.fetch.wait.max.ms = 500
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m 	num.recovery.threads.per.data.dir = 1
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m 	ssl.keystore.type = JKS
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m 	default.replication.factor = 1
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m 	ssl.truststore.password = null
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m 	log.preallocate = false
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m 	ssl.endpoint.identification.algorithm = null
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m 	replica.socket.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m 	message.max.bytes = 1000012
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m 	num.io.threads = 8
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m 	offsets.commit.required.acks = -1
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m 	delete.topic.enable = true
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m 	quota.window.size.seconds = 1
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m 	ssl.truststore.type = JKS
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m 	offsets.commit.timeout.ms = 5000
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	quota.window.num = 11
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	zookeeper.connect = localhost:2181
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m 	authorizer.class.name = 
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m 	num.replica.fetchers = 1
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m 	log.retention.ms = null
[32mkafka_1            |[0m 	log.roll.jitter.hours = 0
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m 	log.cleaner.enable = true
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m 	offsets.load.buffer.size = 5242880
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m 	log.cleaner.delete.retention.ms = 86400000
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m 	ssl.client.auth = none
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaJsonSerializer
[32mkafka_1            |[0m 	controlled.shutdown.max.retries = 3
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m 	queued.max.requests = 500
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m 	offsets.topic.replication.factor = 3
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m 	log.cleaner.threads = 1
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m 	socket.request.max.bytes = 104857600
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,975] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	ssl.trustmanager.algorithm = PKIX
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,975] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	zookeeper.session.timeout.ms = 6000
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,975] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	log.retention.bytes = -1
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,975] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m 	log.message.timestamp.type = CreateTime
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,975] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mrest-proxy_1       |[0m [2019-11-19 15:26:43,975] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[32mkafka_1            |[0m 	zookeeper.set.acl = false
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,104] INFO KafkaAvroSerializerConfig values: 
[32mkafka_1            |[0m 	connections.max.idle.ms = 600000
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m 	offsets.retention.minutes = 1440
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m 	replica.fetch.backoff.ms = 1000
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig:135)
[32mkafka_1            |[0m 	inter.broker.protocol.version = 0.10.0-IV1
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,109] INFO KafkaAvroSerializerConfig values: 
[32mkafka_1            |[0m 	log.retention.hours = 168
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m 	num.partitions = 1
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig:135)
[32mkafka_1            |[0m 	broker.id.generation.enable = true
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,109] INFO ProducerConfig values: 
[32mkafka_1            |[0m 	listeners = null
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	ssl.provider = null
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m 	log.roll.ms = null
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m 	ssl.cipher.suites = null
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	log.index.size.max.bytes = 10485760
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m 	ssl.keymanager.algorithm = SunX509
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m 	replica.fetch.max.bytes = 1048576
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	advertised.port = null
[32mkafka_1            |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[36mrest-proxy_1       |[0m 	client.id = 
[32mkafka_1            |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	log.cleaner.io.buffer.size = 524288
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	zookeeper.connection.timeout.ms = 6000
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	log.roll.hours = 168
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m 	log.cleanup.policy = delete
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m 	host.name = 
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m 	log.roll.jitter.ms = null
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[32mkafka_1            |[0m 	max.connections.per.ip = 2147483647
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m 	offsets.topic.segment.bytes = 104857600
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m 	background.threads = 10
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m 	quota.consumer.default = 9223372036854775807
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m 	request.timeout.ms = 30000
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m 	log.message.format.version = 0.10.0-IV1
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m 	log.index.interval.bytes = 4096
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m 	log.dir = /tmp/kafka-logs
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m 	log.segment.bytes = 1073741824
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mkafka_1            |[0m 	log.cleaner.backoff.ms = 15000
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m 	offset.metadata.max.bytes = 4096
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[32mkafka_1            |[0m 	ssl.truststore.location = null
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m 	group.max.session.timeout.ms = 300000
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m 	ssl.keystore.password = null
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m 	zookeeper.sync.time.ms = 2000
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m 	port = 9092
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m 	log.retention.minutes = null
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m 	log.segment.delete.delay.ms = 60000
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m 	log.dirs = /var/lib/kafka
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m 	controlled.shutdown.enable = true
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m 	compression.type = producer
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m 	max.connections.per.ip.overrides = 
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mkafka_1            |[0m 	auto.leader.rebalance.enable = true
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m 	leader.imbalance.check.interval.seconds = 300
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m 	replica.lag.time.max.ms = 10000
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m 	num.network.threads = 3
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m 	ssl.key.password = null
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m 	reserved.broker.max.id = 1000
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,113] INFO ProducerConfig values: 
[32mkafka_1            |[0m 	metrics.num.samples = 2
[36mrest-proxy_1       |[0m 	metric.reporters = []
[32mkafka_1            |[0m 	socket.send.buffer.bytes = 102400
[36mrest-proxy_1       |[0m 	metadata.max.age.ms = 300000
[32mkafka_1            |[0m 	ssl.protocol = TLS
[36mrest-proxy_1       |[0m 	reconnect.backoff.ms = 50
[32mkafka_1            |[0m 	socket.receive.buffer.bytes = 102400
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mkafka_1            |[0m 	ssl.keystore.location = null
[36mrest-proxy_1       |[0m 	bootstrap.servers = [PLAINTEXT://rohit-X406UAR:9092]
[32mkafka_1            |[0m 	replica.fetch.min.bytes = 1
[36mrest-proxy_1       |[0m 	ssl.keystore.type = JKS
[32mkafka_1            |[0m 	broker.rack = null
[36mrest-proxy_1       |[0m 	sasl.mechanism = GSSAPI
[32mkafka_1            |[0m 	unclean.leader.election.enable = true
[36mrest-proxy_1       |[0m 	max.block.ms = 60000
[32mkafka_1            |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[36mrest-proxy_1       |[0m 	interceptor.classes = null
[32mkafka_1            |[0m 	group.min.session.timeout.ms = 6000
[32mkafka_1            |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36mrest-proxy_1       |[0m 	ssl.truststore.password = null
[32mkafka_1            |[0m 	offsets.retention.check.interval.ms = 600000
[36mrest-proxy_1       |[0m 	client.id = producer-3
[32mkafka_1            |[0m 	producer.purgatory.purge.interval.requests = 1000
[36mrest-proxy_1       |[0m 	ssl.endpoint.identification.algorithm = null
[32mkafka_1            |[0m 	metrics.sample.window.ms = 30000
[36mrest-proxy_1       |[0m 	request.timeout.ms = 30000
[32mkafka_1            |[0m 	broker.id = 0
[36mrest-proxy_1       |[0m 	acks = 1
[32mkafka_1            |[0m 	offsets.topic.compression.codec = 0
[36mrest-proxy_1       |[0m 	receive.buffer.bytes = 32768
[32mkafka_1            |[0m 	log.retention.check.interval.ms = 300000
[36mrest-proxy_1       |[0m 	ssl.truststore.type = JKS
[32mkafka_1            |[0m 	advertised.listeners = null
[36mrest-proxy_1       |[0m 	retries = 0
[32mkafka_1            |[0m 	leader.imbalance.per.broker.percentage = 10
[36mrest-proxy_1       |[0m 	ssl.truststore.location = null
[32mkafka_1            |[0m  (kafka.server.KafkaConfig)
[36mrest-proxy_1       |[0m 	ssl.keystore.password = null
[32mkafka_1            |[0m [2019-11-19 15:26:32,865] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[36mrest-proxy_1       |[0m 	send.buffer.bytes = 131072
[36mrest-proxy_1       |[0m 	compression.type = none
[32mkafka_1            |[0m [2019-11-19 15:26:32,865] INFO starting (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	metadata.fetch.timeout.ms = 60000
[32mkafka_1            |[0m [2019-11-19 15:26:32,872] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[36mrest-proxy_1       |[0m 	retry.backoff.ms = 100
[32mkafka_1            |[0m [2019-11-19 15:26:32,882] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[36mrest-proxy_1       |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mkafka_1            |[0m [2019-11-19 15:26:32,887] INFO Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	buffer.memory = 33554432
[32mkafka_1            |[0m [2019-11-19 15:26:32,887] INFO Client environment:host.name=rohit-X406UAR (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	timeout.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:26:32,887] INFO Client environment:java.version=1.8.0_91 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-19 15:26:32,887] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.service.name = null
[32mkafka_1            |[0m [2019-11-19 15:26:32,887] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mrest-proxy_1       |[0m 	ssl.trustmanager.algorithm = PKIX
[32mkafka_1            |[0m [2019-11-19 15:26:32,887] INFO Client environment:java.class.path=:/usr/bin/../share/java/kafka/jetty-http-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/lz4-1.3.0.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.3.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-3.0.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-javadoc.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/httpcore-4.4.3.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.2.4.jar:/usr/bin/../share/java/kafka/commons-lang3-3.1.jar:/usr/bin/../share/java/kafka/commons-validator-1.4.1.jar:/usr/bin/../share/java/kafka/jackson-databind-2.6.3.jar:/usr/bin/../share/java/kafka/commons-compress-1.4.1.jar:/usr/bin/../share/java/kafka/jersey-guava-2.22.2.jar:/usr/bin/../share/java/kafka/support-metrics-common-3.0.0.jar:/usr/bin/../share/java/kafka/javassist-3.18.2-GA.jar:/usr/bin/../share/java/kafka/jersey-server-2.22.2.jar:/usr/bin/../share/java/kafka/connect-runtime-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.22.2.jar:/usr/bin/../share/java/kafka/connect-api-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/zkclient-0.8.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.2.jar:/usr/bin/../share/java/kafka/reflections-0.9.10.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.21.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/argparse4j-0.5.0.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.6.jar:/usr/bin/../share/java/kafka/commons-digester-1.8.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.4.0-b34.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/javax.inject-1.jar:/usr/bin/../share/java/kafka/jetty-util-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/hk2-api-2.4.0-b34.jar:/usr/bin/../share/java/kafka/rocksdbjni-4.4.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.6.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.22.2.jar:/usr/bin/../share/java/kafka/jetty-security-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/connect-file-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.inject-2.4.0-b34.jar:/usr/bin/../share/java/kafka/scala-parser-combinators_2.11-1.0.4.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-test-sources.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.6.0.jar:/usr/bin/../share/java/kafka/xz-1.0.jar:/usr/bin/../share/java/kafka/validation-api-1.1.0.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka-clients-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jetty-io-9.2.15.v20160210.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.6.3.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.6.3.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.1.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/avro-1.7.7.jar:/usr/bin/../share/java/kafka/kafka-tools-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/jersey-common-2.22.2.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.4.0-b34.jar:/usr/bin/../share/java/kafka/commons-codec-1.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.22.2.jar:/usr/bin/../share/java/kafka/scala-library-2.11.8.jar:/usr/bin/../share/java/kafka/connect-json-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/kafka_2.11-0.10.0.0-cp1-scaladoc.jar:/usr/bin/../share/java/kafka/hk2-locator-2.4.0-b34.jar:/usr/bin/../share/java/kafka/guava-18.0.jar:/usr/bin/../share/java/kafka/httpclient-4.5.1.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/jackson-core-2.6.3.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.8.3.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-0.10.0.0-cp1.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.0.1.jar:/usr/bin/../share/java/kafka/jopt-simple-4.9.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/httpmime-4.5.1.jar:/usr/bin/../share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar:/usr/share/java/confluent-support-metrics/support-metrics-fullcollector-3.0.0.jar (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	block.on.buffer.full = false
[36mrest-proxy_1       |[0m 	ssl.key.password = null
[32mkafka_1            |[0m [2019-11-19 15:26:32,887] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mkafka_1            |[0m [2019-11-19 15:26:32,887] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	connections.max.idle.ms = 540000
[32mkafka_1            |[0m [2019-11-19 15:26:32,888] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	max.in.flight.requests.per.connection = 5
[32mkafka_1            |[0m [2019-11-19 15:26:32,888] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	metrics.num.samples = 2
[32mkafka_1            |[0m [2019-11-19 15:26:32,888] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.protocol = TLS
[32mkafka_1            |[0m [2019-11-19 15:26:32,888] INFO Client environment:os.version=5.0.0-36-generic (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.provider = null
[32mkafka_1            |[0m [2019-11-19 15:26:32,888] INFO Client environment:user.name=confluent (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mkafka_1            |[0m [2019-11-19 15:26:32,888] INFO Client environment:user.home=/home/confluent (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	batch.size = 16384
[32mkafka_1            |[0m [2019-11-19 15:26:32,888] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.keystore.location = null
[32mkafka_1            |[0m [2019-11-19 15:26:32,888] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@63355449 (org.apache.zookeeper.ZooKeeper)
[36mrest-proxy_1       |[0m 	ssl.cipher.suites = null
[32mkafka_1            |[0m [2019-11-19 15:26:32,900] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m 	security.protocol = PLAINTEXT
[32mkafka_1            |[0m [2019-11-19 15:26:32,902] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	max.request.size = 1048576
[32mkafka_1            |[0m [2019-11-19 15:26:32,977] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
[32mkafka_1            |[0m [2019-11-19 15:26:33,040] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16e8445b9100000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[36mrest-proxy_1       |[0m 	ssl.keymanager.algorithm = SunX509
[32mkafka_1            |[0m [2019-11-19 15:26:33,042] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
[36mrest-proxy_1       |[0m 	metrics.sample.window.ms = 30000
[32mkafka_1            |[0m [2019-11-19 15:26:33,207] INFO Loading logs. (kafka.log.LogManager)
[36mrest-proxy_1       |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mkafka_1            |[0m [2019-11-19 15:26:33,236] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	linger.ms = 0
[32mkafka_1            |[0m [2019-11-19 15:26:33,243] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m  (org.apache.kafka.clients.producer.ProducerConfig:178)
[32mkafka_1            |[0m [2019-11-19 15:26:33,246] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,113] WARN The configuration schema.registry.url = http://localhost:8081 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-19 15:26:33,250] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,114] WARN The configuration zookeeper.connect = localhost:2181 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-19 15:26:33,253] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,114] WARN The configuration port = 8082 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-19 15:26:33,256] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,114] WARN The configuration id = 1 was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:186)
[32mkafka_1            |[0m [2019-11-19 15:26:33,259] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,114] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser:83)
[32mkafka_1            |[0m [2019-11-19 15:26:33,262] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,114] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser:84)
[32mkafka_1            |[0m [2019-11-19 15:26:33,265] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,127] INFO Verifying properties (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-19 15:26:33,268] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,130] INFO Property group.id is overridden to  (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-19 15:26:33,271] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,131] WARN Property id is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m [2019-11-19 15:26:33,273] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,131] WARN Property port is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m [2019-11-19 15:26:33,276] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,131] WARN Property schema.registry.url is not valid (kafka.utils.VerifiableProperties:83)
[32mkafka_1            |[0m [2019-11-19 15:26:33,279] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,131] INFO Property zookeeper.connect is overridden to  (kafka.utils.VerifiableProperties:68)
[32mkafka_1            |[0m [2019-11-19 15:26:33,282] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,136] INFO KafkaAvroDeserializerConfig values: 
[32mkafka_1            |[0m [2019-11-19 15:26:33,285] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	schema.registry.url = [http://localhost:8081]
[32mkafka_1            |[0m [2019-11-19 15:26:33,287] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	max.schemas.per.subject = 1000
[32mkafka_1            |[0m [2019-11-19 15:26:33,290] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	specific.avro.reader = false
[32mkafka_1            |[0m [2019-11-19 15:26:33,292] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig:135)
[32mkafka_1            |[0m [2019-11-19 15:26:33,295] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,138] INFO KafkaJsonDecoderConfig values: 
[32mkafka_1            |[0m [2019-11-19 15:26:33,298] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m 	json.fail.unknown.properties = true
[32mkafka_1            |[0m [2019-11-19 15:26:33,301] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m  (io.confluent.kafka.serializers.KafkaJsonDecoderConfig:135)
[32mkafka_1            |[0m [2019-11-19 15:26:33,313] INFO Completed load of log mysimbdp-0 with log end offset 524 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,163] INFO Logging initialized @1086ms (org.eclipse.jetty.util.log:186)
[32mkafka_1            |[0m [2019-11-19 15:26:33,316] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,175] WARN DEPRECATION warning: `listeners` configuration is not configured. Falling back to the deprecated `port` configuration. (io.confluent.rest.Application:248)
[32mkafka_1            |[0m [2019-11-19 15:26:33,321] INFO Completed load of log _schemas-0 with log end offset 1 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,175] INFO Adding listener: http://0.0.0.0:8082 (io.confluent.rest.Application:137)
[32mkafka_1            |[0m [2019-11-19 15:26:33,324] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,228] INFO jetty-9.2.12.v20150709 (org.eclipse.jetty.server.Server:327)
[32mkafka_1            |[0m [2019-11-19 15:26:33,326] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,751] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version:27)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,947] INFO Started o.e.j.s.ServletContextHandler@26f96b85{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:744)
[32mkafka_1            |[0m [2019-11-19 15:26:33,329] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,953] INFO Started NetworkTrafficServerConnector@7e7f0f0a{HTTP/1.1}{0.0.0.0:8082} (org.eclipse.jetty.server.NetworkTrafficServerConnector:266)
[32mkafka_1            |[0m [2019-11-19 15:26:33,333] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,953] INFO Started @1877ms (org.eclipse.jetty.server.Server:379)
[32mkafka_1            |[0m [2019-11-19 15:26:33,336] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 15:26:44,954] INFO Server started, listening for requests... (io.confluent.kafkarest.KafkaRestMain:38)
[32mkafka_1            |[0m [2019-11-19 15:26:33,339] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 18:50:46,053] INFO Stopped NetworkTrafficServerConnector@7e7f0f0a{HTTP/1.1}{0.0.0.0:8082} (org.eclipse.jetty.server.NetworkTrafficServerConnector:306)
[32mkafka_1            |[0m [2019-11-19 15:26:33,341] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 18:50:46,064] INFO Stopped o.e.j.s.ServletContextHandler@26f96b85{/,null,UNAVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:865)
[32mkafka_1            |[0m [2019-11-19 15:26:33,344] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 18:50:46,067] INFO Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[32mkafka_1            |[0m [2019-11-19 15:26:33,346] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 18:50:46,069] INFO Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[32mkafka_1            |[0m [2019-11-19 15:26:33,349] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 18:50:46,071] INFO Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:658)
[32mkafka_1            |[0m [2019-11-19 15:26:33,352] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 18:50:46,073] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread:82)
[32mkafka_1            |[0m [2019-11-19 15:26:33,355] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 18:50:46,079] INFO Session: 0x16e8445b9100002 closed (org.apache.zookeeper.ZooKeeper:679)
[32mkafka_1            |[0m [2019-11-19 15:26:33,357] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[36mrest-proxy_1       |[0m [2019-11-19 18:50:46,079] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn:511)
[32mkafka_1            |[0m [2019-11-19 15:26:33,359] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,366] INFO Completed load of log mysimbdp-clientReport-0 with log end offset 131 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,370] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,373] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,376] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,389] INFO Completed load of log __consumer_offsets-17 with log end offset 194 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,391] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,393] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,395] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,397] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,400] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,403] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,407] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,409] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,412] INFO Completed load of log spark.out-0 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,414] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[32mkafka_1            |[0m [2019-11-19 15:26:33,416] INFO Logs loading complete. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-19 15:26:33,488] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-19 15:26:33,489] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-19 15:26:33,521] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[32mkafka_1            |[0m [2019-11-19 15:26:33,526] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[32mkafka_1            |[0m [2019-11-19 15:26:33,543] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 15:26:33,543] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 15:26:33,589] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[32mkafka_1            |[0m [2019-11-19 15:26:33,603] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[32mkafka_1            |[0m [2019-11-19 15:26:33,604] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[32mkafka_1            |[0m [2019-11-19 15:26:34,301] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 15:26:34,301] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[32mkafka_1            |[0m [2019-11-19 15:26:34,302] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 15:26:34,327] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
[32mkafka_1            |[0m [2019-11-19 15:26:34,328] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
[32mkafka_1            |[0m [2019-11-19 15:26:34,329] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,342] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 15:26:34,343] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 15:26:34,347] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[32mkafka_1            |[0m [2019-11-19 15:26:34,365] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[32mkafka_1            |[0m [2019-11-19 15:26:34,377] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[32mkafka_1            |[0m [2019-11-19 15:26:34,378] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(rohit-X406UAR,9092,PLAINTEXT) (kafka.utils.ZkUtils)
[32mkafka_1            |[0m [2019-11-19 15:26:34,390] INFO Kafka version : 0.10.0.0-cp1 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka_1            |[0m [2019-11-19 15:26:34,390] INFO Kafka commitId : 7aeb2e89dbc741f6 (org.apache.kafka.common.utils.AppInfoParser)
[32mkafka_1            |[0m [2019-11-19 15:26:34,391] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[32mkafka_1            |[0m [2019-11-19 15:26:34,543] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[mysimbdp,0],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[mysimbdp-clientReport,0],[__consumer_offsets,35],[_schemas,0],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[spark.out,0],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,812] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,22] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,819] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,820] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,25] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,822] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,823] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,28] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,826] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,826] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,31] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,829] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,829] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,34] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,832] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,832] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,37] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,835] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,835] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,40] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,839] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,839] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,43] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,843] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,843] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,46] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,846] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,846] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,49] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,849] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,850] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,41] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,854] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,855] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,44] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,858] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,860] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,47] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,863] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,864] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,1] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,868] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,869] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,4] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,872] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,872] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,7] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,876] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,876] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,10] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,879] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,879] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,13] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,883] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,883] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,16] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,886] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,886] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,19] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,889] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,890] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,2] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,893] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,893] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,5] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,901] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 8 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,901] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,8] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,902] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[mysimbdp,0],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[mysimbdp-clientReport,0],[__consumer_offsets,35],[_schemas,0],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[spark.out,0],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,905] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,906] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,11] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,909] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,909] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,14] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,912] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,913] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,17] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,940] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 26 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,941] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,20] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,943] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,943] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,23] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,946] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,946] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,26] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,948] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,948] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,29] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,951] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,951] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,32] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,954] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,954] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,35] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,957] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,957] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,38] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,960] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,960] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,963] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,963] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,966] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,966] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,968] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,969] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,971] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,971] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,996] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 25 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,996] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,997] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,997] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,998] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,998] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,999] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:34,999] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,001] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,001] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,002] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,002] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,003] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,003] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,004] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,005] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,006] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,007] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,008] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,008] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,009] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,009] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,010] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,010] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:26:35,011] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:36:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:46:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 15:56:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 16:06:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 16:16:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 16:26:34,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 16:36:34,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 16:46:34,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 16:56:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 17:06:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 17:16:34,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 17:26:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 17:36:34,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 17:46:34,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 17:56:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 18:06:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 18:16:34,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 18:26:34,325] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 18:36:34,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 18:46:34,324] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[32mkafka_1            |[0m [2019-11-19 18:50:46,694] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[32mkafka_1            |[0m [2019-11-19 18:50:46,695] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[32mkafka_1            |[0m [2019-11-19 18:50:46,719] INFO [Kafka Server 0], Controlled shutdown succeeded (kafka.server.KafkaServer)
[32mkafka_1            |[0m [2019-11-19 18:50:46,722] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[32mkafka_1            |[0m [2019-11-19 18:50:46,728] INFO [Socket Server on Broker 0], Shutdown completed (kafka.network.SocketServer)
[32mkafka_1            |[0m [2019-11-19 18:50:46,730] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[32mkafka_1            |[0m [2019-11-19 18:50:46,732] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[32mkafka_1            |[0m [2019-11-19 18:50:46,735] INFO [ThrottledRequestReaper-Produce], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:47,517] INFO [ThrottledRequestReaper-Produce], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:47,517] INFO [ThrottledRequestReaper-Fetch], Shutting down (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:47,517] INFO [ThrottledRequestReaper-Produce], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,514] INFO [ThrottledRequestReaper-Fetch], Shutdown completed (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,514] INFO [ThrottledRequestReaper-Fetch], Stopped  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,517] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[32mkafka_1            |[0m [2019-11-19 18:50:48,520] INFO [Replica Manager on Broker 0]: Shutting down (kafka.server.ReplicaManager)
[32mkafka_1            |[0m [2019-11-19 18:50:48,521] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[32mkafka_1            |[0m [2019-11-19 18:50:48,524] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[32mkafka_1            |[0m [2019-11-19 18:50:48,524] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,656] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,656] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,656] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,717] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,717] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,721] INFO [Replica Manager on Broker 0]: Shut down completely (kafka.server.ReplicaManager)
[32mkafka_1            |[0m [2019-11-19 18:50:48,723] INFO Shutting down. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-19 18:50:48,769] INFO Shutdown complete. (kafka.log.LogManager)
[32mkafka_1            |[0m [2019-11-19 18:50:48,770] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.GroupCoordinator)
[32mkafka_1            |[0m [2019-11-19 18:50:48,770] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,916] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,916] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,916] INFO [ExpirationReaper-0], Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,917] INFO [ExpirationReaper-0], Stopped  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,917] INFO [ExpirationReaper-0], Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,920] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.GroupCoordinator)
[32mkafka_1            |[0m [2019-11-19 18:50:48,936] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
[32mkafka_1            |[0m [2019-11-19 18:50:48,940] INFO Session: 0x16e8445b9100000 closed (org.apache.zookeeper.ZooKeeper)
[32mkafka_1            |[0m [2019-11-19 18:50:48,942] INFO EventThread shut down (org.apache.zookeeper.ClientCnxn)
[32mkafka_1            |[0m [2019-11-19 18:50:48,944] INFO [Kafka Server 0], shut down completed (kafka.server.KafkaServer)
